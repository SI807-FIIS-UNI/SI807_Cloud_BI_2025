# ğŸ“˜ README -- Pipeline de IntroducciÃ³n a AWS (Grupo 8)

## ğŸ¯ Objetivo

Implementar un flujo inicial de procesamiento de datos en **AWS**, desde
la carga del dataset hasta la catalogaciÃ³n y preparaciÃ³n para anÃ¡lisis,
utilizando **S3 y Glue** como principales servicios.

El flujo esperado del laboratorio es:

    S3 (raw) â†’ Glue Crawler â†’ Glue Data Catalog â†’ S3 (curated)

## ğŸ§± 1. Estructura creada en S3

    s3://si807u-grupo8-bi/
    â”œâ”€â”€ raw/
    â”‚   â””â”€â”€ ecommerce/
    â”œâ”€â”€ curated/
    â”‚   â””â”€â”€ ecommerce/
    â”œâ”€â”€ analytics/
    â”‚   â””â”€â”€ results/
    â””â”€â”€ athena_results/

## 2. Proceso ejecutado

### 1ï¸âƒ£ PreparaciÃ³n del dataset

-   Dataset original: Amazon Sale Report.csv
-   Resultado del EDA: ecommerce_clean.csv

### 2ï¸âƒ£ Carga de datos en S3

Archivo cargado en:

    s3://si807u-grupo8-bi/raw/ecommerce/ecommerce_clean.csv

### 3ï¸âƒ£ Glue Data Catalog

-   Base creada: raw_db
-   Crawler configurado con la ruta raw/ecommerce/
-   â— El crawler no logrÃ³ crear la tabla por un error no identificado

## ğŸš§ Trabajo Pendiente

-   Resolver el error del Crawler
-   Job PySpark
-   Athena
-   QuickSight

## âœ”ï¸ ConclusiÃ³n

Se configurÃ³ correctamente S3 y Glue, pero el pipeline se detuvo por el
error del Crawler.
