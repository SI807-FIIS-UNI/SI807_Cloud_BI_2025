{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de71a235",
   "metadata": {},
   "source": [
    "# Limpieza y Preprocesamiento de Datos\n",
    "\n",
    "Este notebook realiza un proceso completo de limpieza de datos sobre el dataset de ventas. Se aplican técnicas profesionales para garantizar la calidad de los datos antes del análisis exploratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6346a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d83f0c",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos Originales\n",
    "\n",
    "Cargamos el dataset raw desde el archivo CSV. Utilizamos `encoding='latin1'` porque el archivo contiene caracteres especiales en nombres de clientes y direcciones que no están en UTF-8 estándar. La clase `Path` de pathlib nos permite manejar rutas de archivos de forma multiplataforma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data/raw/sales_data_sample.csv')\n",
    "df = pd.read_csv(data_path, encoding='latin1')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e5213",
   "metadata": {},
   "source": [
    "## 2. Inspección Inicial de Datos\n",
    "\n",
    "Realizamos una exploración preliminar del dataset para entender su estructura, tipos de datos y obtener estadísticas descriptivas básicas. Esto nos ayuda a identificar posibles problemas antes de aplicar la limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a34328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1426ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c410d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08180309",
   "metadata": {},
   "source": [
    "## 3. Análisis de Valores Nulos\n",
    "\n",
    "Identificamos valores faltantes en cada columna. Calculamos tanto el conteo absoluto como el porcentaje de valores nulos para priorizar qué columnas requieren tratamiento. Esta información es crucial para decidir si eliminar, imputar o mantener registros con datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Missing_Percentage': missing_pct\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"Missing values summary:\")\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "missing_cols = missing_df[missing_df['Missing_Count'] > 0]\n",
    "if not missing_cols.empty:\n",
    "    missing_cols['Missing_Percentage'].plot(kind='bar')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c9d58",
   "metadata": {},
   "source": [
    "## 4. Tratamiento de Valores Nulos\n",
    "\n",
    "Aplicamos estrategias diferenciadas según el tipo de columna. Para campos opcionales como STATE y POSTALCODE (que pueden no existir en ciertos países), rellenamos con 'Unknown'. Para campos críticos del negocio (ORDERNUMBER, SALES, ORDERDATE, CUSTOMERNAME), eliminamos registros incompletos ya que son esenciales para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# STATE and POSTALCODE can be missing for some countries\n",
    "if 'STATE' in df_clean.columns:\n",
    "    df_clean['STATE'].fillna('Unknown', inplace=True)\n",
    "\n",
    "if 'POSTALCODE' in df_clean.columns:\n",
    "    df_clean['POSTALCODE'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Drop rows with critical missing values\n",
    "critical_cols = ['ORDERNUMBER', 'SALES', 'ORDERDATE', 'CUSTOMERNAME']\n",
    "df_clean.dropna(subset=critical_cols, inplace=True)\n",
    "\n",
    "print(f\"Records after handling missing values: {len(df_clean)}\")\n",
    "print(f\"Records dropped: {len(df) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706a69d",
   "metadata": {},
   "source": [
    "## 5. Conversión de Tipos de Datos\n",
    "\n",
    "Convertimos columnas a sus tipos de datos apropiados. ORDERDATE se transforma a datetime para permitir operaciones temporales. Los identificadores numéricos (YEAR_ID, MONTH_ID, QTR_ID) se convierten a enteros para asegurar consistencia en cálculos y agrupaciones posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712826ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['ORDERDATE'] = pd.to_datetime(df_clean['ORDERDATE'])\n",
    "df_clean['YEAR_ID'] = df_clean['YEAR_ID'].astype(int)\n",
    "df_clean['MONTH_ID'] = df_clean['MONTH_ID'].astype(int)\n",
    "df_clean['QTR_ID'] = df_clean['QTR_ID'].astype(int)\n",
    "\n",
    "print(\"Data types after conversion:\")\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d664d0c",
   "metadata": {},
   "source": [
    "## 6. Detección de Valores Atípicos\n",
    "\n",
    "Utilizamos diagramas de caja (boxplots) para visualizar la distribución de variables numéricas clave. Luego aplicamos el método IQR (Rango Intercuartílico) para identificar outliers estadísticos. Los valores fuera del rango [Q1 - 1.5*IQR, Q3 + 1.5*IQR] se consideran atípicos, aunque no necesariamente erróneos en contextos de negocio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede02ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['QUANTITYORDERED', 'PRICEEACH', 'SALES']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    axes[idx].boxplot(df_clean[col].dropna())\n",
    "    axes[idx].set_title(f'{col}')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b3b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "for col in numeric_cols:\n",
    "    outliers = detect_outliers_iqr(df_clean, col)\n",
    "    print(f\"{col}: {len(outliers)} outliers ({len(outliers)/len(df_clean)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d03d86",
   "metadata": {},
   "source": [
    "## 7. Detección de Duplicados\n",
    "\n",
    "Verificamos la existencia de registros completamente duplicados utilizando el método `duplicated()`. Los duplicados exactos pueden indicar errores en la carga de datos o en el sistema transaccional. Si se encuentran, se eliminan para evitar sesgos en análisis agregados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa37d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df_clean.duplicated().sum()\n",
    "print(f\"Total duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    df_clean.drop_duplicates(inplace=True)\n",
    "    print(f\"Duplicates removed. New shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edadc1d",
   "metadata": {},
   "source": [
    "## 8. Validación de Integridad de Datos\n",
    "\n",
    "Validamos reglas de negocio básicas: las cantidades, precios y ventas deben ser positivos. Identificamos registros que violan estas restricciones y los eliminamos, ya que representan datos corruptos o inconsistencias del sistema que no tienen sentido en el contexto comercial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ad3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate numeric values\n",
    "invalid_qty = df_clean[df_clean['QUANTITYORDERED'] <= 0]\n",
    "invalid_price = df_clean[df_clean['PRICEEACH'] <= 0]\n",
    "invalid_sales = df_clean[df_clean['SALES'] <= 0]\n",
    "\n",
    "print(f\"Invalid quantities: {len(invalid_qty)}\")\n",
    "print(f\"Invalid prices: {len(invalid_price)}\")\n",
    "print(f\"Invalid sales: {len(invalid_sales)}\")\n",
    "\n",
    "# Remove invalid records\n",
    "df_clean = df_clean[\n",
    "    (df_clean['QUANTITYORDERED'] > 0) &\n",
    "    (df_clean['PRICEEACH'] > 0) &\n",
    "    (df_clean['SALES'] > 0)\n",
    "]\n",
    "\n",
    "print(f\"\\nRecords after validation: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7130088",
   "metadata": {},
   "source": [
    "## 9. Ingeniería de Características\n",
    "\n",
    "Creamos nuevas variables derivadas de ORDERDATE para facilitar análisis temporales: año, mes, día, día de la semana y trimestre. También calculamos REVENUE_PER_UNIT (ingreso por unidad) dividiendo SALES entre QUANTITYORDERED, una métrica útil para análisis de rentabilidad por producto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['ORDER_YEAR'] = df_clean['ORDERDATE'].dt.year\n",
    "df_clean['ORDER_MONTH'] = df_clean['ORDERDATE'].dt.month\n",
    "df_clean['ORDER_DAY'] = df_clean['ORDERDATE'].dt.day\n",
    "df_clean['ORDER_DAYOFWEEK'] = df_clean['ORDERDATE'].dt.dayofweek\n",
    "df_clean['ORDER_QUARTER'] = df_clean['ORDERDATE'].dt.quarter\n",
    "\n",
    "# Revenue per unit\n",
    "df_clean['REVENUE_PER_UNIT'] = df_clean['SALES'] / df_clean['QUANTITYORDERED']\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(df_clean[['ORDER_YEAR', 'ORDER_MONTH', 'ORDER_QUARTER', 'REVENUE_PER_UNIT']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb68e14",
   "metadata": {},
   "source": [
    "## 10. Reporte Final de Calidad de Datos\n",
    "\n",
    "Generamos un resumen comparativo entre el dataset original y el limpio. Calculamos métricas de retención de datos para evaluar cuánta información se perdió durante la limpieza. Un porcentaje de retención alto (>95%) indica que la limpieza fue quirúrgica y no agresiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20cda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original records: {len(df)}\")\n",
    "print(f\"Final records: {len(df_clean)}\")\n",
    "print(f\"Records removed: {len(df) - len(df_clean)}\")\n",
    "print(f\"Retention rate: {len(df_clean)/len(df)*100:.2f}%\")\n",
    "print(f\"\\nFinal shape: {df_clean.shape}\")\n",
    "print(f\"Missing values: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e4a6b",
   "metadata": {},
   "source": [
    "## 11. Exportación de Datos Limpios\n",
    "\n",
    "Guardamos el dataset procesado en formato CSV con encoding UTF-8 en el directorio processed. Este archivo será la fuente de datos para todos los análisis posteriores. También reportamos el tamaño del archivo para validar que la exportación fue exitosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('../data/processed/sales_data_clean.csv')\n",
    "df_clean.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"Cleaned data saved to: {output_path}\")\n",
    "print(f\"File size: {output_path.stat().st_size / 1024:.2f} KB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
