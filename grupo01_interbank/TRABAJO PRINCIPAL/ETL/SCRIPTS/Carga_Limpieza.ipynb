{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21443115-3408-4ee6-8eb7-9a7cd12ae893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/17 15:31:26 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/11/17 15:31:26 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/11/17 15:31:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/11/17 15:31:26 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso de limpieza de datos...\n",
      "Archivo de entrada: /ProyectoPrincipal/cli_cambios.csv\n",
      "Archivo de salida: gs://grupo01-project-sin/processed/cli_cambios_limpio.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo leído exitosamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dimensiones iniciales: 5163 filas x 7 columnas\n",
      "\n",
      "Esquema inicial:\n",
      "root\n",
      " |-- fecha: timestamp (nullable = true)\n",
      " |-- codigo unico: integer (nullable = true)\n",
      " |-- RUC: integer (nullable = true)\n",
      " |-- Nombre: string (nullable = true)\n",
      " |-- TIPO: string (nullable = true)\n",
      " |-- Utilidad: double (nullable = true)\n",
      " |-- VOL_USD: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contando valores nulos iniciales...\n",
      "  fecha (timestamp): 0 nulls\n",
      "  codigo unico (int): 0 nulls\n",
      "  RUC (int): 0 nulls\n",
      "  Nombre (string): 0 nulls\n",
      "  TIPO (string): 0 nulls\n",
      "  Utilidad (double): 0 nulls\n",
      "  VOL_USD (double): 0 nulls\n",
      "\n",
      "Total de valores nulos iniciales: 0\n",
      "\n",
      "--- Iniciando limpieza ---\n",
      "1. Limpiando nombres de columnas...\n",
      "  ✓ Columnas renombradas: 7 columnas\n",
      "2. Eliminando filas completamente vacías...\n",
      "  ✓ Filas vacías eliminadas: 0\n",
      "3. Eliminando duplicados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Filas duplicadas eliminadas: 0\n",
      "4. Limpiando datos por tipo de columna...\n",
      "  Procesando columna 'fecha' (tipo: timestamp)\n",
      "  Procesando columna 'codigo_unico' (tipo: int)\n",
      "  Procesando columna 'ruc' (tipo: int)\n",
      "  Procesando columna 'nombre' (tipo: string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Procesando columna 'tipo' (tipo: string)\n",
      "  Procesando columna 'utilidad' (tipo: double)\n",
      "  Procesando columna 'vol_usd' (tipo: double)\n",
      "  ✓ Procesamiento de columnas completado\n",
      "5. Verificando columnas completamente vacías...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ No hay columnas completamente vacías\n",
      "\n",
      "Contando valores nulos finales...\n",
      "Total de valores nulos finales: 0\n",
      "\n",
      "--- Guardando resultado ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo guardado exitosamente en: gs://grupo01-project-sin/processed/cli_cambios_limpio.parquet\n",
      "\n",
      "============================================================\n",
      "           REPORTE DE LIMPIEZA - PYSPARK\n",
      "============================================================\n",
      "Archivo original: /ProyectoPrincipal/cli_cambios.csv\n",
      "Archivo limpio: gs://grupo01-project-sin/processed/cli_cambios_limpio.parquet\n",
      "------------------------------------------------------------\n",
      "ESTADÍSTICAS:\n",
      "  Filas iniciales:           5,163\n",
      "  Filas finales:             5,163\n",
      "  Filas eliminadas:          0\n",
      "  Filas vacías eliminadas:   0\n",
      "  Filas duplicadas elim.:    0\n",
      "\n",
      "  Columnas iniciales:        7\n",
      "  Columnas finales:          7\n",
      "  Columnas eliminadas:       0\n",
      "\n",
      "  Valores nulos iniciales:   0\n",
      "  Valores nulos finales:     0\n",
      "  Valores nulos limpiados:   0\n",
      "------------------------------------------------------------\n",
      "CAMBIOS EN VALORES NULOS POR COLUMNA:\n",
      "\n",
      "ESQUEMA FINAL:\n",
      "root\n",
      " |-- fecha: timestamp (nullable = true)\n",
      " |-- codigo_unico: integer (nullable = true)\n",
      " |-- ruc: integer (nullable = true)\n",
      " |-- nombre: string (nullable = true)\n",
      " |-- tipo: string (nullable = true)\n",
      " |-- utilidad: double (nullable = true)\n",
      " |-- vol_usd: double (nullable = true)\n",
      "\n",
      "MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\n",
      "+-------------------+------------+--------+------------+----+--------+-------+\n",
      "|fecha              |codigo_unico|ruc     |nombre      |tipo|utilidad|vol_usd|\n",
      "+-------------------+------------+--------+------------+----+--------+-------+\n",
      "|2025-01-12 00:00:00|1363        |38348817|empresa 416 |v   |4396.65 |4970.14|\n",
      "|2025-02-09 00:00:00|410         |63386038|empresa 296 |v   |143.86  |1107.52|\n",
      "|2025-03-01 00:00:00|1345        |33387092|empresa 1357|v   |765.0   |1480.08|\n",
      "|2025-05-11 00:00:00|295         |15853584|empresa 570 |c   |529.86  |1957.28|\n",
      "|2025-05-29 00:00:00|123         |56321408|empresa 109 |c   |3650.02 |4565.85|\n",
      "+-------------------+------------+--------+------------+----+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "============================================================\n",
      "✓ LIMPIEZA COMPLETADA EXITOSAMENTE\n",
      "============================================================\n",
      "\n",
      "✓ Sesión de Spark cerrada\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim, lower, when, lit, isnan\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, FloatType, TimestampType, DateType\n",
    "import re\n",
    "\n",
    "# Configurar Spark para Dataproc\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LimpiezaTradingCSV\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurar nivel de log para reducir output\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# RUTAS\n",
    "ruta_input = \"/ProyectoPrincipal/cli_cambios.csv\" \n",
    "ruta_output = \"gs://grupo01-project-sin/processed/cli_cambios_limpio.parquet\"\n",
    "\n",
    "print(\"Iniciando proceso de limpieza de datos...\")\n",
    "print(f\"Archivo de entrada: {ruta_input}\")\n",
    "print(f\"Archivo de salida: {ruta_output}\")\n",
    "\n",
    "try:\n",
    "    # -------------------------------------\n",
    "    # A. LECTURA DE DATOS\n",
    "    # -------------------------------------\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"multiline\", \"true\") \\\n",
    "        .option(\"escape\", '\"') \\\n",
    "        .csv(ruta_input)\n",
    "    \n",
    "    print(f\"✓ Archivo leído exitosamente\")\n",
    "    print(f\"  Dimensiones iniciales: {df.count()} filas x {len(df.columns)} columnas\")\n",
    "    \n",
    "    # Mostrar esquema inicial\n",
    "    print(\"\\nEsquema inicial:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Estadísticas iniciales\n",
    "    initial_rows = df.count()\n",
    "    initial_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls iniciales de forma simple\n",
    "    print(\"\\nContando valores nulos iniciales...\")\n",
    "    total_initial_nulls = 0\n",
    "    null_counts_initial = {}\n",
    "    \n",
    "    for column_name, data_type in df.dtypes:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_initial[column_name] = null_count\n",
    "            total_initial_nulls += null_count\n",
    "            print(f\"  {column_name} ({data_type}): {null_count} nulls\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls en {column_name}: {e}\")\n",
    "            null_counts_initial[column_name] = 0\n",
    "    \n",
    "    print(f\"\\nTotal de valores nulos iniciales: {total_initial_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # B. PROCESO DE LIMPIEZA \n",
    "    # -------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Iniciando limpieza ---\")\n",
    "    \n",
    "    # 1. LIMPIAR NOMBRES DE COLUMNAS\n",
    "    print(\"1. Limpiando nombres de columnas...\")\n",
    "    columns_before = df.columns\n",
    "    \n",
    "    # Función para limpiar nombres de columnas\n",
    "    def clean_column_name(col_name):\n",
    "        clean_name = re.sub(r'[^\\w\\s]', '', str(col_name).strip().lower())\n",
    "        clean_name = re.sub(r'\\s+', '_', clean_name)\n",
    "        return clean_name if clean_name else f\"col_{hash(col_name) % 1000}\"\n",
    "    \n",
    "    new_columns = [clean_column_name(c) for c in df.columns]\n",
    "    \n",
    "    # Verificar que no haya nombres duplicados\n",
    "    seen = set()\n",
    "    final_columns = []\n",
    "    for i, col_name in enumerate(new_columns):\n",
    "        original_name = col_name\n",
    "        counter = 1\n",
    "        while col_name in seen:\n",
    "            col_name = f\"{original_name}_{counter}\"\n",
    "            counter += 1\n",
    "        seen.add(col_name)\n",
    "        final_columns.append(col_name)\n",
    "    \n",
    "    df = df.toDF(*final_columns)\n",
    "    print(f\"  ✓ Columnas renombradas: {len(columns_before)} columnas\")\n",
    "    \n",
    "    # 2. ELIMINAR FILAS COMPLETAMENTE VACÍAS\n",
    "    print(\"2. Eliminando filas completamente vacías...\")\n",
    "    try:\n",
    "        df_before_empty = df.count()\n",
    "        df = df.na.drop(\"all\")\n",
    "        df_after_empty = df.count()\n",
    "        empty_rows_removed = df_before_empty - df_after_empty\n",
    "        print(f\"  ✓ Filas vacías eliminadas: {empty_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando filas vacías: {e}\")\n",
    "        empty_rows_removed = 0\n",
    "    \n",
    "    # 3. ELIMINAR DUPLICADOS\n",
    "    print(\"3. Eliminando duplicados...\")\n",
    "    try:\n",
    "        rows_before_dedup = df.count()\n",
    "        df = df.dropDuplicates()\n",
    "        rows_after_dedup = df.count()\n",
    "        duplicate_rows_removed = rows_before_dedup - rows_after_dedup\n",
    "        print(f\"  ✓ Filas duplicadas eliminadas: {duplicate_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando duplicados: {e}\")\n",
    "        duplicate_rows_removed = 0\n",
    "    \n",
    "    # 4. LIMPIAR DATOS POR TIPO DE COLUMNA\n",
    "    print(\"4. Limpiando datos por tipo de columna...\")\n",
    "    \n",
    "    # Valores a considerar como nulos para strings\n",
    "    invalid_vals = [\"\", \" \", \"na\", \"n/a\", \"null\", \"none\", \"nan\", \"undefined\", \"nil\", \"-\", \"NULL\", \"None\"]\n",
    "    \n",
    "    # Obtener tipos actualizados después del renombrado\n",
    "    current_dtypes = df.dtypes\n",
    "    \n",
    "    # Procesar cada columna según su tipo\n",
    "    for column_name, data_type in current_dtypes:\n",
    "        try:\n",
    "            print(f\"  Procesando columna '{column_name}' (tipo: {data_type})\")\n",
    "            \n",
    "            if data_type == \"string\":\n",
    "                # Limpiar columnas de texto\n",
    "                df = df.withColumn(column_name, \n",
    "                                 when(col(column_name).isNull(), lit(None))\n",
    "                                 .otherwise(trim(lower(col(column_name)))))\n",
    "                \n",
    "                # Reemplazar valores inválidos por null\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isin(invalid_vals), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "            elif data_type in [\"double\", \"float\"]:\n",
    "                # Limpiar columnas numéricas decimales\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isNull() | isnan(col(column_name)), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Error procesando columna {column_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"  ✓ Procesamiento de columnas completado\")\n",
    "    \n",
    "    # 5. ELIMINAR COLUMNAS COMPLETAMENTE VACÍAS (opcional)\n",
    "    print(\"5. Verificando columnas completamente vacías...\")\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    try:\n",
    "        current_row_count = df.count()\n",
    "        for column_name in df.columns:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            if null_count == current_row_count and current_row_count > 0:\n",
    "                columns_to_drop.append(column_name)\n",
    "        \n",
    "        if columns_to_drop:\n",
    "            df = df.drop(*columns_to_drop)\n",
    "            print(f\"  ✓ Columnas completamente vacías eliminadas: {columns_to_drop}\")\n",
    "        else:\n",
    "            print(f\"  ✓ No hay columnas completamente vacías\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error verificando columnas vacías: {e}\")\n",
    "        columns_to_drop = []\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # C. ESTADÍSTICAS FINALES\n",
    "    # -------------------------------------\n",
    "    final_rows = df.count()\n",
    "    final_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls finales de forma simple\n",
    "    print(\"\\nContando valores nulos finales...\")\n",
    "    total_final_nulls = 0\n",
    "    null_counts_final = {}\n",
    "    \n",
    "    for column_name in df.columns:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_final[column_name] = null_count\n",
    "            total_final_nulls += null_count\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls finales en {column_name}: {e}\")\n",
    "            null_counts_final[column_name] = 0\n",
    "    \n",
    "    print(f\"Total de valores nulos finales: {total_final_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # D. GUARDAR RESULTADO\n",
    "    # -------------------------------------\n",
    "    print(\"\\n--- Guardando resultado ---\")\n",
    "    \n",
    "    try:\n",
    "        # Intentar guardar con coalesce\n",
    "        df.coalesce(1).write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"compression\", \"snappy\") \\\n",
    "            .parquet(ruta_output)\n",
    "        \n",
    "        print(f\"✓ Archivo guardado exitosamente en: {ruta_output}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error con coalesce, intentando sin coalesce: {e}\")\n",
    "        try:\n",
    "            # Intentar guardar sin coalesce\n",
    "            df.write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .option(\"compression\", \"snappy\") \\\n",
    "                .parquet(ruta_output)\n",
    "            print(f\" Archivo guardado (sin coalesce) en: {ruta_output}\")\n",
    "        except Exception as e2:\n",
    "            print(f\" Error guardando archivo: {e2}\")\n",
    "            raise e2\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # E. REPORTE FINAL\n",
    "    # -------------------------------------\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"           REPORTE DE LIMPIEZA - PYSPARK\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Archivo original: {ruta_input}\")\n",
    "    print(f\"Archivo limpio: {ruta_output}\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"ESTADÍSTICAS:\")\n",
    "    print(f\"  Filas iniciales:           {initial_rows:,}\")\n",
    "    print(f\"  Filas finales:             {final_rows:,}\")\n",
    "    print(f\"  Filas eliminadas:          {initial_rows - final_rows:,}\")\n",
    "    print(f\"  Filas vacías eliminadas:   {empty_rows_removed:,}\")\n",
    "    print(f\"  Filas duplicadas elim.:    {duplicate_rows_removed:,}\")\n",
    "    print()\n",
    "    print(f\"  Columnas iniciales:        {initial_cols}\")\n",
    "    print(f\"  Columnas finales:          {final_cols}\")\n",
    "    print(f\"  Columnas eliminadas:       {len(columns_to_drop)}\")\n",
    "    print()\n",
    "    print(f\"  Valores nulos iniciales:   {total_initial_nulls:,}\")\n",
    "    print(f\"  Valores nulos finales:     {total_final_nulls:,}\")\n",
    "    print(f\"  Valores nulos limpiados:   {max(0, total_initial_nulls - total_final_nulls):,}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Mostrar detalle de nulls por columna (solo las que cambiaron)\n",
    "    print(\"CAMBIOS EN VALORES NULOS POR COLUMNA:\")\n",
    "    for column_name in df.columns:\n",
    "        initial = null_counts_initial.get(column_name, 0)\n",
    "        final = null_counts_final.get(column_name, 0)\n",
    "        if initial != final:\n",
    "            print(f\"  {column_name}: {initial} → {final}\")\n",
    "    \n",
    "    # Mostrar esquema final\n",
    "    try:\n",
    "        print(\"\\nESQUEMA FINAL:\")\n",
    "        df.printSchema()\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar el esquema: {e}\")\n",
    "    \n",
    "    # Mostrar muestra de datos\n",
    "    try:\n",
    "        print(\"MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\")\n",
    "        df.show(5, truncate=False)\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar muestra de datos: {e}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\" LIMPIEZA COMPLETADA EXITOSAMENTE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error durante el proceso de limpieza: {str(e)}\")\n",
    "    print(\"Detalles del error:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Cerrar Spark session\n",
    "    try:\n",
    "        spark.stop()\n",
    "        print(\"\\n Sesión de Spark cerrada\")\n",
    "    except:\n",
    "        print(\"\\n Sesión cerrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "691aec1f-4c1f-4a4d-a1a9-864181c63329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/17 15:54:12 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/11/17 15:54:12 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/11/17 15:54:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/11/17 15:54:12 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso de limpieza de datos...\n",
      "Archivo de entrada: /ProyectoPrincipal/registro_comunicaciones_new_v2.csv\n",
      "Archivo de salida: gs://grupo01-project-sin/processed/registro_comunicaciones_limpio.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo leído exitosamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dimensiones iniciales: 518 filas x 6 columnas\n",
      "\n",
      "Esquema inicial:\n",
      "root\n",
      " |-- Tipo Cliente: string (nullable = true)\n",
      " |-- Especificacion: string (nullable = true)\n",
      " |-- Cantidad: integer (nullable = true)\n",
      " |-- Dia: timestamp (nullable = true)\n",
      " |-- Estado: string (nullable = true)\n",
      " |-- Card: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contando valores nulos iniciales...\n",
      "  Tipo Cliente (string): 0 nulls\n",
      "  Especificacion (string): 0 nulls\n",
      "  Cantidad (int): 0 nulls\n",
      "  Dia (timestamp): 0 nulls\n",
      "  Estado (string): 0 nulls\n",
      "  Card (string): 0 nulls\n",
      "\n",
      "Total de valores nulos iniciales: 0\n",
      "\n",
      "--- Iniciando limpieza ---\n",
      "1. Limpiando nombres de columnas...\n",
      "  ✓ Columnas renombradas: 6 columnas\n",
      "2. Eliminando filas completamente vacías...\n",
      "  ✓ Filas vacías eliminadas: 0\n",
      "3. Eliminando duplicados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Filas duplicadas eliminadas: 0\n",
      "4. Limpiando datos por tipo de columna...\n",
      "  Procesando columna 'tipo_cliente' (tipo: string)\n",
      "  Procesando columna 'especificacion' (tipo: string)\n",
      "  Procesando columna 'cantidad' (tipo: int)\n",
      "  Procesando columna 'dia' (tipo: timestamp)\n",
      "  Procesando columna 'estado' (tipo: string)\n",
      "  Procesando columna 'card' (tipo: string)\n",
      "  ✓ Procesamiento de columnas completado\n",
      "5. Verificando columnas completamente vacías...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ No hay columnas completamente vacías\n",
      "\n",
      "Contando valores nulos finales...\n",
      "Total de valores nulos finales: 0\n",
      "\n",
      "--- Guardando resultado ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo guardado exitosamente en: gs://grupo01-project-sin/processed/registro_comunicaciones_limpio.parquet\n",
      "\n",
      "============================================================\n",
      "           REPORTE DE LIMPIEZA - PYSPARK\n",
      "============================================================\n",
      "Archivo original: /ProyectoPrincipal/registro_comunicaciones_new_v2.csv\n",
      "Archivo limpio: gs://grupo01-project-sin/processed/registro_comunicaciones_limpio.parquet\n",
      "------------------------------------------------------------\n",
      "ESTADÍSTICAS:\n",
      "  Filas iniciales:           518\n",
      "  Filas finales:             518\n",
      "  Filas eliminadas:          0\n",
      "  Filas vacías eliminadas:   0\n",
      "  Filas duplicadas elim.:    0\n",
      "\n",
      "  Columnas iniciales:        6\n",
      "  Columnas finales:          6\n",
      "  Columnas eliminadas:       0\n",
      "\n",
      "  Valores nulos iniciales:   0\n",
      "  Valores nulos finales:     0\n",
      "  Valores nulos limpiados:   0\n",
      "------------------------------------------------------------\n",
      "CAMBIOS EN VALORES NULOS POR COLUMNA:\n",
      "\n",
      "ESQUEMA FINAL:\n",
      "root\n",
      " |-- tipo_cliente: string (nullable = true)\n",
      " |-- especificacion: string (nullable = true)\n",
      " |-- cantidad: integer (nullable = true)\n",
      " |-- dia: timestamp (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- card: string (nullable = true)\n",
      "\n",
      "MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\n",
      "+------------+--------------+--------+-------------------+-------+---------+\n",
      "|tipo_cliente|especificacion|cantidad|dia                |estado |card     |\n",
      "+------------+--------------+--------+-------------------+-------+---------+\n",
      "|fintech     |sms           |316     |2025-02-18 00:00:00|enviado|cd-787281|\n",
      "|estrella    |sms           |9883    |2025-04-24 00:00:00|enviado|cd-228232|\n",
      "|estrella    |html          |11000   |2025-08-12 00:00:00|enviado|cd-653091|\n",
      "|churn       |sms           |1885    |2025-09-15 00:00:00|enviado|cd-937393|\n",
      "|churn       |html          |16282   |2025-02-04 00:00:00|enviado|cd-437497|\n",
      "+------------+--------------+--------+-------------------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "============================================================\n",
      "✓ LIMPIEZA COMPLETADA EXITOSAMENTE\n",
      "============================================================\n",
      "\n",
      " Sesión de Spark cerrada\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim, lower, when, lit, isnan\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, FloatType, TimestampType, DateType\n",
    "import re\n",
    "\n",
    "# Configurar Spark para Dataproc\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LimpiezaTradingCSV\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurar nivel de log para reducir output\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# RUTAS\n",
    "ruta_input = \"/ProyectoPrincipal/registro_comunicaciones_new_v2.csv\" \n",
    "ruta_output = \"gs://grupo01-project-sin/processed/registro_comunicaciones_limpio.parquet\"\n",
    "\n",
    "print(\"Iniciando proceso de limpieza de datos...\")\n",
    "print(f\"Archivo de entrada: {ruta_input}\")\n",
    "print(f\"Archivo de salida: {ruta_output}\")\n",
    "\n",
    "try:\n",
    "    # -------------------------------------\n",
    "    # A. LECTURA DE DATOS\n",
    "    # -------------------------------------\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"multiline\", \"true\") \\\n",
    "        .option(\"escape\", '\"') \\\n",
    "        .csv(ruta_input)\n",
    "    \n",
    "    print(f\"✓ Archivo leído exitosamente\")\n",
    "    print(f\"  Dimensiones iniciales: {df.count()} filas x {len(df.columns)} columnas\")\n",
    "    \n",
    "    # Mostrar esquema inicial\n",
    "    print(\"\\nEsquema inicial:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Estadísticas iniciales\n",
    "    initial_rows = df.count()\n",
    "    initial_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls iniciales de forma simple\n",
    "    print(\"\\nContando valores nulos iniciales...\")\n",
    "    total_initial_nulls = 0\n",
    "    null_counts_initial = {}\n",
    "    \n",
    "    for column_name, data_type in df.dtypes:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_initial[column_name] = null_count\n",
    "            total_initial_nulls += null_count\n",
    "            print(f\"  {column_name} ({data_type}): {null_count} nulls\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls en {column_name}: {e}\")\n",
    "            null_counts_initial[column_name] = 0\n",
    "    \n",
    "    print(f\"\\nTotal de valores nulos iniciales: {total_initial_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # B. PROCESO DE LIMPIEZA \n",
    "    # -------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Iniciando limpieza ---\")\n",
    "    \n",
    "    # 1. LIMPIAR NOMBRES DE COLUMNAS\n",
    "    print(\"1. Limpiando nombres de columnas...\")\n",
    "    columns_before = df.columns\n",
    "    \n",
    "    # Función para limpiar nombres de columnas\n",
    "    def clean_column_name(col_name):\n",
    "        clean_name = re.sub(r'[^\\w\\s]', '', str(col_name).strip().lower())\n",
    "        clean_name = re.sub(r'\\s+', '_', clean_name)\n",
    "        return clean_name if clean_name else f\"col_{hash(col_name) % 1000}\"\n",
    "    \n",
    "    new_columns = [clean_column_name(c) for c in df.columns]\n",
    "    \n",
    "    # Verificar que no haya nombres duplicados\n",
    "    seen = set()\n",
    "    final_columns = []\n",
    "    for i, col_name in enumerate(new_columns):\n",
    "        original_name = col_name\n",
    "        counter = 1\n",
    "        while col_name in seen:\n",
    "            col_name = f\"{original_name}_{counter}\"\n",
    "            counter += 1\n",
    "        seen.add(col_name)\n",
    "        final_columns.append(col_name)\n",
    "    \n",
    "    df = df.toDF(*final_columns)\n",
    "    print(f\"  ✓ Columnas renombradas: {len(columns_before)} columnas\")\n",
    "    \n",
    "    # 2. ELIMINAR FILAS COMPLETAMENTE VACÍAS\n",
    "    print(\"2. Eliminando filas completamente vacías...\")\n",
    "    try:\n",
    "        df_before_empty = df.count()\n",
    "        df = df.na.drop(\"all\")\n",
    "        df_after_empty = df.count()\n",
    "        empty_rows_removed = df_before_empty - df_after_empty\n",
    "        print(f\"  ✓ Filas vacías eliminadas: {empty_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando filas vacías: {e}\")\n",
    "        empty_rows_removed = 0\n",
    "    \n",
    "    # 3. ELIMINAR DUPLICADOS\n",
    "    print(\"3. Eliminando duplicados...\")\n",
    "    try:\n",
    "        rows_before_dedup = df.count()\n",
    "        df = df.dropDuplicates()\n",
    "        rows_after_dedup = df.count()\n",
    "        duplicate_rows_removed = rows_before_dedup - rows_after_dedup\n",
    "        print(f\"  ✓ Filas duplicadas eliminadas: {duplicate_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando duplicados: {e}\")\n",
    "        duplicate_rows_removed = 0\n",
    "    \n",
    "    # 4. LIMPIAR DATOS POR TIPO DE COLUMNA\n",
    "    print(\"4. Limpiando datos por tipo de columna...\")\n",
    "    \n",
    "    # Valores a considerar como nulos para strings\n",
    "    invalid_vals = [\"\", \" \", \"na\", \"n/a\", \"null\", \"none\", \"nan\", \"undefined\", \"nil\", \"-\", \"NULL\", \"None\"]\n",
    "    \n",
    "    # Obtener tipos actualizados después del renombrado\n",
    "    current_dtypes = df.dtypes\n",
    "    \n",
    "    # Procesar cada columna según su tipo\n",
    "    for column_name, data_type in current_dtypes:\n",
    "        try:\n",
    "            print(f\"  Procesando columna '{column_name}' (tipo: {data_type})\")\n",
    "            \n",
    "            if data_type == \"string\":\n",
    "                # Limpiar columnas de texto\n",
    "                df = df.withColumn(column_name, \n",
    "                                 when(col(column_name).isNull(), lit(None))\n",
    "                                 .otherwise(trim(lower(col(column_name)))))\n",
    "                \n",
    "                # Reemplazar valores inválidos por null\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isin(invalid_vals), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "            elif data_type in [\"double\", \"float\"]:\n",
    "                # Limpiar columnas numéricas decimales\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isNull() | isnan(col(column_name)), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Error procesando columna {column_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"  ✓ Procesamiento de columnas completado\")\n",
    "    \n",
    "    # 5. ELIMINAR COLUMNAS COMPLETAMENTE VACÍAS (opcional)\n",
    "    print(\"5. Verificando columnas completamente vacías...\")\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    try:\n",
    "        current_row_count = df.count()\n",
    "        for column_name in df.columns:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            if null_count == current_row_count and current_row_count > 0:\n",
    "                columns_to_drop.append(column_name)\n",
    "        \n",
    "        if columns_to_drop:\n",
    "            df = df.drop(*columns_to_drop)\n",
    "            print(f\"  ✓ Columnas completamente vacías eliminadas: {columns_to_drop}\")\n",
    "        else:\n",
    "            print(f\"  ✓ No hay columnas completamente vacías\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error verificando columnas vacías: {e}\")\n",
    "        columns_to_drop = []\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # C. ESTADÍSTICAS FINALES\n",
    "    # -------------------------------------\n",
    "    final_rows = df.count()\n",
    "    final_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls finales de forma simple\n",
    "    print(\"\\nContando valores nulos finales...\")\n",
    "    total_final_nulls = 0\n",
    "    null_counts_final = {}\n",
    "    \n",
    "    for column_name in df.columns:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_final[column_name] = null_count\n",
    "            total_final_nulls += null_count\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls finales en {column_name}: {e}\")\n",
    "            null_counts_final[column_name] = 0\n",
    "    \n",
    "    print(f\"Total de valores nulos finales: {total_final_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # D. GUARDAR RESULTADO\n",
    "    # -------------------------------------\n",
    "    print(\"\\n--- Guardando resultado ---\")\n",
    "    \n",
    "    try:\n",
    "        # Intentar guardar con coalesce\n",
    "        df.coalesce(1).write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"compression\", \"snappy\") \\\n",
    "            .parquet(ruta_output)\n",
    "        \n",
    "        print(f\"✓ Archivo guardado exitosamente en: {ruta_output}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error con coalesce, intentando sin coalesce: {e}\")\n",
    "        try:\n",
    "            # Intentar guardar sin coalesce\n",
    "            df.write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .option(\"compression\", \"snappy\") \\\n",
    "                .parquet(ruta_output)\n",
    "            print(f\" Archivo guardado (sin coalesce) en: {ruta_output}\")\n",
    "        except Exception as e2:\n",
    "            print(f\" Error guardando archivo: {e2}\")\n",
    "            raise e2\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # E. REPORTE FINAL\n",
    "    # -------------------------------------\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"           REPORTE DE LIMPIEZA - PYSPARK\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Archivo original: {ruta_input}\")\n",
    "    print(f\"Archivo limpio: {ruta_output}\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"ESTADÍSTICAS:\")\n",
    "    print(f\"  Filas iniciales:           {initial_rows:,}\")\n",
    "    print(f\"  Filas finales:             {final_rows:,}\")\n",
    "    print(f\"  Filas eliminadas:          {initial_rows - final_rows:,}\")\n",
    "    print(f\"  Filas vacías eliminadas:   {empty_rows_removed:,}\")\n",
    "    print(f\"  Filas duplicadas elim.:    {duplicate_rows_removed:,}\")\n",
    "    print()\n",
    "    print(f\"  Columnas iniciales:        {initial_cols}\")\n",
    "    print(f\"  Columnas finales:          {final_cols}\")\n",
    "    print(f\"  Columnas eliminadas:       {len(columns_to_drop)}\")\n",
    "    print()\n",
    "    print(f\"  Valores nulos iniciales:   {total_initial_nulls:,}\")\n",
    "    print(f\"  Valores nulos finales:     {total_final_nulls:,}\")\n",
    "    print(f\"  Valores nulos limpiados:   {max(0, total_initial_nulls - total_final_nulls):,}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Mostrar detalle de nulls por columna (solo las que cambiaron)\n",
    "    print(\"CAMBIOS EN VALORES NULOS POR COLUMNA:\")\n",
    "    for column_name in df.columns:\n",
    "        initial = null_counts_initial.get(column_name, 0)\n",
    "        final = null_counts_final.get(column_name, 0)\n",
    "        if initial != final:\n",
    "            print(f\"  {column_name}: {initial} → {final}\")\n",
    "    \n",
    "    # Mostrar esquema final\n",
    "    try:\n",
    "        print(\"\\nESQUEMA FINAL:\")\n",
    "        df.printSchema()\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar el esquema: {e}\")\n",
    "    \n",
    "    # Mostrar muestra de datos\n",
    "    try:\n",
    "        print(\"MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\")\n",
    "        df.show(5, truncate=False)\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar muestra de datos: {e}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"✓ LIMPIEZA COMPLETADA EXITOSAMENTE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error durante el proceso de limpieza: {str(e)}\")\n",
    "    print(\"Detalles del error:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Cerrar Spark session\n",
    "    try:\n",
    "        spark.stop()\n",
    "        print(\"\\n Sesión de Spark cerrada\")\n",
    "    except:\n",
    "        print(\"\\n Sesión cerrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b5f8d2e-f42a-4bd6-832a-80230c466517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/17 15:56:28 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/11/17 15:56:28 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/11/17 15:56:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/11/17 15:56:28 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso de limpieza de datos...\n",
      "Archivo de entrada: /ProyectoPrincipal/segmentos_v2.csv\n",
      "Archivo de salida: gs://grupo01-project-sin/processed/segmentos_limpio.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo leído exitosamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dimensiones iniciales: 12239 filas x 10 columnas\n",
      "\n",
      "Esquema inicial:\n",
      "root\n",
      " |-- Periodo: integer (nullable = true)\n",
      " |-- Codigo Unico: integer (nullable = true)\n",
      " |-- Ruc: integer (nullable = true)\n",
      " |-- Jefe: string (nullable = true)\n",
      " |-- Ejecutivo: string (nullable = true)\n",
      " |-- Segmento FX: string (nullable = true)\n",
      " |-- Tipo Cuenta: string (nullable = true)\n",
      " |-- Logeo: integer (nullable = true)\n",
      " |-- Num Logeos: integer (nullable = true)\n",
      " |-- Flg Dig: integer (nullable = true)\n",
      "\n",
      "\n",
      "Contando valores nulos iniciales...\n",
      "  Periodo (int): 0 nulls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Codigo Unico (int): 0 nulls\n",
      "  Ruc (int): 0 nulls\n",
      "  Jefe (string): 0 nulls\n",
      "  Ejecutivo (string): 0 nulls\n",
      "  Segmento FX (string): 0 nulls\n",
      "  Tipo Cuenta (string): 0 nulls\n",
      "  Logeo (int): 0 nulls\n",
      "  Num Logeos (int): 0 nulls\n",
      "  Flg Dig (int): 0 nulls\n",
      "\n",
      "Total de valores nulos iniciales: 0\n",
      "\n",
      "--- Iniciando limpieza ---\n",
      "1. Limpiando nombres de columnas...\n",
      "  ✓ Columnas renombradas: 10 columnas\n",
      "2. Eliminando filas completamente vacías...\n",
      "  ✓ Filas vacías eliminadas: 0\n",
      "3. Eliminando duplicados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Filas duplicadas eliminadas: 0\n",
      "4. Limpiando datos por tipo de columna...\n",
      "  Procesando columna 'periodo' (tipo: int)\n",
      "  Procesando columna 'codigo_unico' (tipo: int)\n",
      "  Procesando columna 'ruc' (tipo: int)\n",
      "  Procesando columna 'jefe' (tipo: string)\n",
      "  Procesando columna 'ejecutivo' (tipo: string)\n",
      "  Procesando columna 'segmento_fx' (tipo: string)\n",
      "  Procesando columna 'tipo_cuenta' (tipo: string)\n",
      "  Procesando columna 'logeo' (tipo: int)\n",
      "  Procesando columna 'num_logeos' (tipo: int)\n",
      "  Procesando columna 'flg_dig' (tipo: int)\n",
      "  ✓ Procesamiento de columnas completado\n",
      "5. Verificando columnas completamente vacías...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ No hay columnas completamente vacías\n",
      "\n",
      "Contando valores nulos finales...\n",
      "Total de valores nulos finales: 0\n",
      "\n",
      "--- Guardando resultado ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo guardado exitosamente en: gs://grupo01-project-sin/processed/segmentos_limpio.parquet\n",
      "\n",
      "============================================================\n",
      "           REPORTE DE LIMPIEZA - PYSPARK\n",
      "============================================================\n",
      "Archivo original: /ProyectoPrincipal/segmentos_v2.csv\n",
      "Archivo limpio: gs://grupo01-project-sin/processed/segmentos_limpio.parquet\n",
      "------------------------------------------------------------\n",
      "ESTADÍSTICAS:\n",
      "  Filas iniciales:           12,239\n",
      "  Filas finales:             12,239\n",
      "  Filas eliminadas:          0\n",
      "  Filas vacías eliminadas:   0\n",
      "  Filas duplicadas elim.:    0\n",
      "\n",
      "  Columnas iniciales:        10\n",
      "  Columnas finales:          10\n",
      "  Columnas eliminadas:       0\n",
      "\n",
      "  Valores nulos iniciales:   0\n",
      "  Valores nulos finales:     0\n",
      "  Valores nulos limpiados:   0\n",
      "------------------------------------------------------------\n",
      "CAMBIOS EN VALORES NULOS POR COLUMNA:\n",
      "\n",
      "ESQUEMA FINAL:\n",
      "root\n",
      " |-- periodo: integer (nullable = true)\n",
      " |-- codigo_unico: integer (nullable = true)\n",
      " |-- ruc: integer (nullable = true)\n",
      " |-- jefe: string (nullable = true)\n",
      " |-- ejecutivo: string (nullable = true)\n",
      " |-- segmento_fx: string (nullable = true)\n",
      " |-- tipo_cuenta: string (nullable = true)\n",
      " |-- logeo: integer (nullable = true)\n",
      " |-- num_logeos: integer (nullable = true)\n",
      " |-- flg_dig: integer (nullable = true)\n",
      "\n",
      "MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\n",
      "+-------+------------+--------+--------------+--------------+-----------+-----------+-----+----------+-------+\n",
      "|periodo|codigo_unico|ruc     |jefe          |ejecutivo     |segmento_fx|tipo_cuenta|logeo|num_logeos|flg_dig|\n",
      "+-------+------------+--------+--------------+--------------+-----------+-----------+-----+----------+-------+\n",
      "|202501 |645         |50480309|antonio pérez |juan pérez    |nuevos     |bimoneda   |1    |245       |1      |\n",
      "|202501 |990         |10953959|paula martínez|andrea jiménez|nuevos     |monomoneda |1    |117       |0      |\n",
      "|202501 |1096        |90535969|ana jiménez   |sofía álvarez |comex      |monomoneda |1    |246       |1      |\n",
      "|202501 |872         |63028791|laura pérez   |jorge muñoz   |churn      |bimoneda   |0    |433       |0      |\n",
      "|202501 |42          |54738553|paula moreno  |andrea muñoz  |comex      |monomoneda |0    |61        |1      |\n",
      "+-------+------------+--------+--------------+--------------+-----------+-----------+-----+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "============================================================\n",
      "✓ LIMPIEZA COMPLETADA EXITOSAMENTE\n",
      "============================================================\n",
      "\n",
      " Sesión de Spark cerrada\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim, lower, when, lit, isnan\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, FloatType, TimestampType, DateType\n",
    "import re\n",
    "\n",
    "# Configurar Spark para Dataproc\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LimpiezaTradingCSV\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurar nivel de log para reducir output\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# RUTAS\n",
    "ruta_input = \"/ProyectoPrincipal/segmentos_v2.csv\" \n",
    "ruta_output = \"gs://grupo01-project-sin/processed/segmentos_limpio.parquet\"\n",
    "\n",
    "print(\"Iniciando proceso de limpieza de datos...\")\n",
    "print(f\"Archivo de entrada: {ruta_input}\")\n",
    "print(f\"Archivo de salida: {ruta_output}\")\n",
    "\n",
    "try:\n",
    "    # -------------------------------------\n",
    "    # A. LECTURA DE DATOS\n",
    "    # -------------------------------------\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"multiline\", \"true\") \\\n",
    "        .option(\"escape\", '\"') \\\n",
    "        .csv(ruta_input)\n",
    "    \n",
    "    print(f\"✓ Archivo leído exitosamente\")\n",
    "    print(f\"  Dimensiones iniciales: {df.count()} filas x {len(df.columns)} columnas\")\n",
    "    \n",
    "    # Mostrar esquema inicial\n",
    "    print(\"\\nEsquema inicial:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Estadísticas iniciales\n",
    "    initial_rows = df.count()\n",
    "    initial_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls iniciales de forma simple\n",
    "    print(\"\\nContando valores nulos iniciales...\")\n",
    "    total_initial_nulls = 0\n",
    "    null_counts_initial = {}\n",
    "    \n",
    "    for column_name, data_type in df.dtypes:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_initial[column_name] = null_count\n",
    "            total_initial_nulls += null_count\n",
    "            print(f\"  {column_name} ({data_type}): {null_count} nulls\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls en {column_name}: {e}\")\n",
    "            null_counts_initial[column_name] = 0\n",
    "    \n",
    "    print(f\"\\nTotal de valores nulos iniciales: {total_initial_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # B. PROCESO DE LIMPIEZA \n",
    "    # -------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Iniciando limpieza ---\")\n",
    "    \n",
    "    # 1. LIMPIAR NOMBRES DE COLUMNAS\n",
    "    print(\"1. Limpiando nombres de columnas...\")\n",
    "    columns_before = df.columns\n",
    "    \n",
    "    # Función para limpiar nombres de columnas\n",
    "    def clean_column_name(col_name):\n",
    "        clean_name = re.sub(r'[^\\w\\s]', '', str(col_name).strip().lower())\n",
    "        clean_name = re.sub(r'\\s+', '_', clean_name)\n",
    "        return clean_name if clean_name else f\"col_{hash(col_name) % 1000}\"\n",
    "    \n",
    "    new_columns = [clean_column_name(c) for c in df.columns]\n",
    "    \n",
    "    # Verificar que no haya nombres duplicados\n",
    "    seen = set()\n",
    "    final_columns = []\n",
    "    for i, col_name in enumerate(new_columns):\n",
    "        original_name = col_name\n",
    "        counter = 1\n",
    "        while col_name in seen:\n",
    "            col_name = f\"{original_name}_{counter}\"\n",
    "            counter += 1\n",
    "        seen.add(col_name)\n",
    "        final_columns.append(col_name)\n",
    "    \n",
    "    df = df.toDF(*final_columns)\n",
    "    print(f\"  ✓ Columnas renombradas: {len(columns_before)} columnas\")\n",
    "    \n",
    "    # 2. ELIMINAR FILAS COMPLETAMENTE VACÍAS\n",
    "    print(\"2. Eliminando filas completamente vacías...\")\n",
    "    try:\n",
    "        df_before_empty = df.count()\n",
    "        df = df.na.drop(\"all\")\n",
    "        df_after_empty = df.count()\n",
    "        empty_rows_removed = df_before_empty - df_after_empty\n",
    "        print(f\"  ✓ Filas vacías eliminadas: {empty_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando filas vacías: {e}\")\n",
    "        empty_rows_removed = 0\n",
    "    \n",
    "    # 3. ELIMINAR DUPLICADOS\n",
    "    print(\"3. Eliminando duplicados...\")\n",
    "    try:\n",
    "        rows_before_dedup = df.count()\n",
    "        df = df.dropDuplicates()\n",
    "        rows_after_dedup = df.count()\n",
    "        duplicate_rows_removed = rows_before_dedup - rows_after_dedup\n",
    "        print(f\"  ✓ Filas duplicadas eliminadas: {duplicate_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando duplicados: {e}\")\n",
    "        duplicate_rows_removed = 0\n",
    "    \n",
    "    # 4. LIMPIAR DATOS POR TIPO DE COLUMNA\n",
    "    print(\"4. Limpiando datos por tipo de columna...\")\n",
    "    \n",
    "    # Valores a considerar como nulos para strings\n",
    "    invalid_vals = [\"\", \" \", \"na\", \"n/a\", \"null\", \"none\", \"nan\", \"undefined\", \"nil\", \"-\", \"NULL\", \"None\"]\n",
    "    \n",
    "    # Obtener tipos actualizados después del renombrado\n",
    "    current_dtypes = df.dtypes\n",
    "    \n",
    "    # Procesar cada columna según su tipo\n",
    "    for column_name, data_type in current_dtypes:\n",
    "        try:\n",
    "            print(f\"  Procesando columna '{column_name}' (tipo: {data_type})\")\n",
    "            \n",
    "            if data_type == \"string\":\n",
    "                # Limpiar columnas de texto\n",
    "                df = df.withColumn(column_name, \n",
    "                                 when(col(column_name).isNull(), lit(None))\n",
    "                                 .otherwise(trim(lower(col(column_name)))))\n",
    "                \n",
    "                # Reemplazar valores inválidos por null\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isin(invalid_vals), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "            elif data_type in [\"double\", \"float\"]:\n",
    "                # Limpiar columnas numéricas decimales\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isNull() | isnan(col(column_name)), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Error procesando columna {column_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"  ✓ Procesamiento de columnas completado\")\n",
    "    \n",
    "    # 5. ELIMINAR COLUMNAS COMPLETAMENTE VACÍAS (opcional)\n",
    "    print(\"5. Verificando columnas completamente vacías...\")\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    try:\n",
    "        current_row_count = df.count()\n",
    "        for column_name in df.columns:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            if null_count == current_row_count and current_row_count > 0:\n",
    "                columns_to_drop.append(column_name)\n",
    "        \n",
    "        if columns_to_drop:\n",
    "            df = df.drop(*columns_to_drop)\n",
    "            print(f\"  ✓ Columnas completamente vacías eliminadas: {columns_to_drop}\")\n",
    "        else:\n",
    "            print(f\"  ✓ No hay columnas completamente vacías\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error verificando columnas vacías: {e}\")\n",
    "        columns_to_drop = []\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # C. ESTADÍSTICAS FINALES\n",
    "    # -------------------------------------\n",
    "    final_rows = df.count()\n",
    "    final_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls finales de forma simple\n",
    "    print(\"\\nContando valores nulos finales...\")\n",
    "    total_final_nulls = 0\n",
    "    null_counts_final = {}\n",
    "    \n",
    "    for column_name in df.columns:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_final[column_name] = null_count\n",
    "            total_final_nulls += null_count\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls finales en {column_name}: {e}\")\n",
    "            null_counts_final[column_name] = 0\n",
    "    \n",
    "    print(f\"Total de valores nulos finales: {total_final_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # D. GUARDAR RESULTADO\n",
    "    # -------------------------------------\n",
    "    print(\"\\n--- Guardando resultado ---\")\n",
    "    \n",
    "    try:\n",
    "        # Intentar guardar con coalesce\n",
    "        df.coalesce(1).write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"compression\", \"snappy\") \\\n",
    "            .parquet(ruta_output)\n",
    "        \n",
    "        print(f\"✓ Archivo guardado exitosamente en: {ruta_output}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error con coalesce, intentando sin coalesce: {e}\")\n",
    "        try:\n",
    "            # Intentar guardar sin coalesce\n",
    "            df.write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .option(\"compression\", \"snappy\") \\\n",
    "                .parquet(ruta_output)\n",
    "            print(f\" Archivo guardado (sin coalesce) en: {ruta_output}\")\n",
    "        except Exception as e2:\n",
    "            print(f\" Error guardando archivo: {e2}\")\n",
    "            raise e2\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # E. REPORTE FINAL\n",
    "    # -------------------------------------\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"           REPORTE DE LIMPIEZA - PYSPARK\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Archivo original: {ruta_input}\")\n",
    "    print(f\"Archivo limpio: {ruta_output}\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"ESTADÍSTICAS:\")\n",
    "    print(f\"  Filas iniciales:           {initial_rows:,}\")\n",
    "    print(f\"  Filas finales:             {final_rows:,}\")\n",
    "    print(f\"  Filas eliminadas:          {initial_rows - final_rows:,}\")\n",
    "    print(f\"  Filas vacías eliminadas:   {empty_rows_removed:,}\")\n",
    "    print(f\"  Filas duplicadas elim.:    {duplicate_rows_removed:,}\")\n",
    "    print()\n",
    "    print(f\"  Columnas iniciales:        {initial_cols}\")\n",
    "    print(f\"  Columnas finales:          {final_cols}\")\n",
    "    print(f\"  Columnas eliminadas:       {len(columns_to_drop)}\")\n",
    "    print()\n",
    "    print(f\"  Valores nulos iniciales:   {total_initial_nulls:,}\")\n",
    "    print(f\"  Valores nulos finales:     {total_final_nulls:,}\")\n",
    "    print(f\"  Valores nulos limpiados:   {max(0, total_initial_nulls - total_final_nulls):,}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Mostrar detalle de nulls por columna (solo las que cambiaron)\n",
    "    print(\"CAMBIOS EN VALORES NULOS POR COLUMNA:\")\n",
    "    for column_name in df.columns:\n",
    "        initial = null_counts_initial.get(column_name, 0)\n",
    "        final = null_counts_final.get(column_name, 0)\n",
    "        if initial != final:\n",
    "            print(f\"  {column_name}: {initial} → {final}\")\n",
    "    \n",
    "    # Mostrar esquema final\n",
    "    try:\n",
    "        print(\"\\nESQUEMA FINAL:\")\n",
    "        df.printSchema()\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar el esquema: {e}\")\n",
    "    \n",
    "    # Mostrar muestra de datos\n",
    "    try:\n",
    "        print(\"MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\")\n",
    "        df.show(5, truncate=False)\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar muestra de datos: {e}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"✓ LIMPIEZA COMPLETADA EXITOSAMENTE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error durante el proceso de limpieza: {str(e)}\")\n",
    "    print(\"Detalles del error:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Cerrar Spark session\n",
    "    try:\n",
    "        spark.stop()\n",
    "        print(\"\\n Sesión de Spark cerrada\")\n",
    "    except:\n",
    "        print(\"\\n Sesión cerrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c010e4c2-ee82-4d0a-8af1-34307c65b829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/17 15:59:03 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/11/17 15:59:03 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/11/17 15:59:03 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/11/17 15:59:03 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso de limpieza de datos...\n",
      "Archivo de entrada: /ProyectoPrincipal/tiendas_ranking_propio_updated.csv\n",
      "Archivo de salida: gs://grupo01-project-sin/processed/tiendas_ranking_limpio.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo leído exitosamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dimensiones iniciales: 55 filas x 9 columnas\n",
      "\n",
      "Esquema inicial:\n",
      "root\n",
      " |-- Canal: string (nullable = true)\n",
      " |-- Posicion: integer (nullable = true)\n",
      " |-- Jefe: string (nullable = true)\n",
      " |-- Ejecutivo: string (nullable = true)\n",
      " |-- Monto: double (nullable = true)\n",
      " |-- Desembolsado: double (nullable = true)\n",
      " |-- Volumen Cambiado: double (nullable = true)\n",
      " |-- Utilidad: double (nullable = true)\n",
      " |-- id_ejecutivo: integer (nullable = true)\n",
      "\n",
      "\n",
      "Contando valores nulos iniciales...\n",
      "  Canal (string): 0 nulls\n",
      "  Posicion (int): 0 nulls\n",
      "  Jefe (string): 0 nulls\n",
      "  Ejecutivo (string): 0 nulls\n",
      "  Monto (double): 0 nulls\n",
      "  Desembolsado (double): 0 nulls\n",
      "  Volumen Cambiado (double): 0 nulls\n",
      "  Utilidad (double): 0 nulls\n",
      "  id_ejecutivo (int): 0 nulls\n",
      "\n",
      "Total de valores nulos iniciales: 0\n",
      "\n",
      "--- Iniciando limpieza ---\n",
      "1. Limpiando nombres de columnas...\n",
      "  ✓ Columnas renombradas: 9 columnas\n",
      "2. Eliminando filas completamente vacías...\n",
      "  ✓ Filas vacías eliminadas: 0\n",
      "3. Eliminando duplicados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Filas duplicadas eliminadas: 0\n",
      "4. Limpiando datos por tipo de columna...\n",
      "  Procesando columna 'canal' (tipo: string)\n",
      "  Procesando columna 'posicion' (tipo: int)\n",
      "  Procesando columna 'jefe' (tipo: string)\n",
      "  Procesando columna 'ejecutivo' (tipo: string)\n",
      "  Procesando columna 'monto' (tipo: double)\n",
      "  Procesando columna 'desembolsado' (tipo: double)\n",
      "  Procesando columna 'volumen_cambiado' (tipo: double)\n",
      "  Procesando columna 'utilidad' (tipo: double)\n",
      "  Procesando columna 'id_ejecutivo' (tipo: int)\n",
      "  ✓ Procesamiento de columnas completado\n",
      "5. Verificando columnas completamente vacías...\n",
      "  ✓ No hay columnas completamente vacías\n",
      "\n",
      "Contando valores nulos finales...\n",
      "Total de valores nulos finales: 0\n",
      "\n",
      "--- Guardando resultado ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo guardado exitosamente en: gs://grupo01-project-sin/processed/tiendas_ranking_limpio.parquet\n",
      "\n",
      "============================================================\n",
      "           REPORTE DE LIMPIEZA - PYSPARK\n",
      "============================================================\n",
      "Archivo original: /ProyectoPrincipal/tiendas_ranking_propio_updated.csv\n",
      "Archivo limpio: gs://grupo01-project-sin/processed/tiendas_ranking_limpio.parquet\n",
      "------------------------------------------------------------\n",
      "ESTADÍSTICAS:\n",
      "  Filas iniciales:           55\n",
      "  Filas finales:             55\n",
      "  Filas eliminadas:          0\n",
      "  Filas vacías eliminadas:   0\n",
      "  Filas duplicadas elim.:    0\n",
      "\n",
      "  Columnas iniciales:        9\n",
      "  Columnas finales:          9\n",
      "  Columnas eliminadas:       0\n",
      "\n",
      "  Valores nulos iniciales:   0\n",
      "  Valores nulos finales:     0\n",
      "  Valores nulos limpiados:   0\n",
      "------------------------------------------------------------\n",
      "CAMBIOS EN VALORES NULOS POR COLUMNA:\n",
      "\n",
      "ESQUEMA FINAL:\n",
      "root\n",
      " |-- canal: string (nullable = true)\n",
      " |-- posicion: integer (nullable = true)\n",
      " |-- jefe: string (nullable = true)\n",
      " |-- ejecutivo: string (nullable = true)\n",
      " |-- monto: double (nullable = true)\n",
      " |-- desembolsado: double (nullable = true)\n",
      " |-- volumen_cambiado: double (nullable = true)\n",
      " |-- utilidad: double (nullable = true)\n",
      " |-- id_ejecutivo: integer (nullable = true)\n",
      "\n",
      "MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\n",
      "+-------+--------+-------------+-----------------+-------+------------+----------------+--------+------------+\n",
      "|canal  |posicion|jefe         |ejecutivo        |monto  |desembolsado|volumen_cambiado|utilidad|id_ejecutivo|\n",
      "+-------+--------+-------------+-----------------+-------+------------+----------------+--------+------------+\n",
      "|tiendas|3       |lucía garcía |antonio hernández|2466.41|18.2        |3041.83         |1797.86 |3           |\n",
      "|tiendas|37      |elena jiménez|luis sánchez     |7147.06|7.67        |3249.52         |863.95  |37          |\n",
      "|tiendas|13      |elena jiménez|marta álvarez    |1164.0 |9.39        |3570.02         |1558.39 |13          |\n",
      "|tiendas|47      |elena ruiz   |manuel díaz      |8725.71|11.61       |4581.36         |450.56  |47          |\n",
      "|tiendas|43      |luis moreno  |marta pérez      |2063.48|14.32       |2441.59         |703.2   |43          |\n",
      "+-------+--------+-------------+-----------------+-------+------------+----------------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "============================================================\n",
      "✓ LIMPIEZA COMPLETADA EXITOSAMENTE\n",
      "============================================================\n",
      "\n",
      " Sesión de Spark cerrada\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim, lower, when, lit, isnan\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, FloatType, TimestampType, DateType\n",
    "import re\n",
    "\n",
    "# Configurar Spark para Dataproc\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LimpiezaTradingCSV\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurar nivel de log para reducir output\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# RUTAS\n",
    "ruta_input = \"/ProyectoPrincipal/tiendas_ranking_propio_updated.csv\" \n",
    "ruta_output = \"gs://grupo01-project-sin/processed/tiendas_ranking_limpio.parquet\"\n",
    "\n",
    "print(\"Iniciando proceso de limpieza de datos...\")\n",
    "print(f\"Archivo de entrada: {ruta_input}\")\n",
    "print(f\"Archivo de salida: {ruta_output}\")\n",
    "\n",
    "try:\n",
    "    # -------------------------------------\n",
    "    # A. LECTURA DE DATOS\n",
    "    # -------------------------------------\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"multiline\", \"true\") \\\n",
    "        .option(\"escape\", '\"') \\\n",
    "        .csv(ruta_input)\n",
    "    \n",
    "    print(f\"✓ Archivo leído exitosamente\")\n",
    "    print(f\"  Dimensiones iniciales: {df.count()} filas x {len(df.columns)} columnas\")\n",
    "    \n",
    "    # Mostrar esquema inicial\n",
    "    print(\"\\nEsquema inicial:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Estadísticas iniciales\n",
    "    initial_rows = df.count()\n",
    "    initial_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls iniciales de forma simple\n",
    "    print(\"\\nContando valores nulos iniciales...\")\n",
    "    total_initial_nulls = 0\n",
    "    null_counts_initial = {}\n",
    "    \n",
    "    for column_name, data_type in df.dtypes:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_initial[column_name] = null_count\n",
    "            total_initial_nulls += null_count\n",
    "            print(f\"  {column_name} ({data_type}): {null_count} nulls\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls en {column_name}: {e}\")\n",
    "            null_counts_initial[column_name] = 0\n",
    "    \n",
    "    print(f\"\\nTotal de valores nulos iniciales: {total_initial_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # B. PROCESO DE LIMPIEZA \n",
    "    # -------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Iniciando limpieza ---\")\n",
    "    \n",
    "    # 1. LIMPIAR NOMBRES DE COLUMNAS\n",
    "    print(\"1. Limpiando nombres de columnas...\")\n",
    "    columns_before = df.columns\n",
    "    \n",
    "    # Función para limpiar nombres de columnas\n",
    "    def clean_column_name(col_name):\n",
    "        clean_name = re.sub(r'[^\\w\\s]', '', str(col_name).strip().lower())\n",
    "        clean_name = re.sub(r'\\s+', '_', clean_name)\n",
    "        return clean_name if clean_name else f\"col_{hash(col_name) % 1000}\"\n",
    "    \n",
    "    new_columns = [clean_column_name(c) for c in df.columns]\n",
    "    \n",
    "    # Verificar que no haya nombres duplicados\n",
    "    seen = set()\n",
    "    final_columns = []\n",
    "    for i, col_name in enumerate(new_columns):\n",
    "        original_name = col_name\n",
    "        counter = 1\n",
    "        while col_name in seen:\n",
    "            col_name = f\"{original_name}_{counter}\"\n",
    "            counter += 1\n",
    "        seen.add(col_name)\n",
    "        final_columns.append(col_name)\n",
    "    \n",
    "    df = df.toDF(*final_columns)\n",
    "    print(f\"  ✓ Columnas renombradas: {len(columns_before)} columnas\")\n",
    "    \n",
    "    # 2. ELIMINAR FILAS COMPLETAMENTE VACÍAS\n",
    "    print(\"2. Eliminando filas completamente vacías...\")\n",
    "    try:\n",
    "        df_before_empty = df.count()\n",
    "        df = df.na.drop(\"all\")\n",
    "        df_after_empty = df.count()\n",
    "        empty_rows_removed = df_before_empty - df_after_empty\n",
    "        print(f\"  ✓ Filas vacías eliminadas: {empty_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando filas vacías: {e}\")\n",
    "        empty_rows_removed = 0\n",
    "    \n",
    "    # 3. ELIMINAR DUPLICADOS\n",
    "    print(\"3. Eliminando duplicados...\")\n",
    "    try:\n",
    "        rows_before_dedup = df.count()\n",
    "        df = df.dropDuplicates()\n",
    "        rows_after_dedup = df.count()\n",
    "        duplicate_rows_removed = rows_before_dedup - rows_after_dedup\n",
    "        print(f\"  ✓ Filas duplicadas eliminadas: {duplicate_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando duplicados: {e}\")\n",
    "        duplicate_rows_removed = 0\n",
    "    \n",
    "    # 4. LIMPIAR DATOS POR TIPO DE COLUMNA\n",
    "    print(\"4. Limpiando datos por tipo de columna...\")\n",
    "    \n",
    "    # Valores a considerar como nulos para strings\n",
    "    invalid_vals = [\"\", \" \", \"na\", \"n/a\", \"null\", \"none\", \"nan\", \"undefined\", \"nil\", \"-\", \"NULL\", \"None\"]\n",
    "    \n",
    "    # Obtener tipos actualizados después del renombrado\n",
    "    current_dtypes = df.dtypes\n",
    "    \n",
    "    # Procesar cada columna según su tipo\n",
    "    for column_name, data_type in current_dtypes:\n",
    "        try:\n",
    "            print(f\"  Procesando columna '{column_name}' (tipo: {data_type})\")\n",
    "            \n",
    "            if data_type == \"string\":\n",
    "                # Limpiar columnas de texto\n",
    "                df = df.withColumn(column_name, \n",
    "                                 when(col(column_name).isNull(), lit(None))\n",
    "                                 .otherwise(trim(lower(col(column_name)))))\n",
    "                \n",
    "                # Reemplazar valores inválidos por null\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isin(invalid_vals), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "            elif data_type in [\"double\", \"float\"]:\n",
    "                # Limpiar columnas numéricas decimales\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isNull() | isnan(col(column_name)), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Error procesando columna {column_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"  ✓ Procesamiento de columnas completado\")\n",
    "    \n",
    "    # 5. ELIMINAR COLUMNAS COMPLETAMENTE VACÍAS (opcional)\n",
    "    print(\"5. Verificando columnas completamente vacías...\")\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    try:\n",
    "        current_row_count = df.count()\n",
    "        for column_name in df.columns:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            if null_count == current_row_count and current_row_count > 0:\n",
    "                columns_to_drop.append(column_name)\n",
    "        \n",
    "        if columns_to_drop:\n",
    "            df = df.drop(*columns_to_drop)\n",
    "            print(f\"  ✓ Columnas completamente vacías eliminadas: {columns_to_drop}\")\n",
    "        else:\n",
    "            print(f\"  ✓ No hay columnas completamente vacías\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error verificando columnas vacías: {e}\")\n",
    "        columns_to_drop = []\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # C. ESTADÍSTICAS FINALES\n",
    "    # -------------------------------------\n",
    "    final_rows = df.count()\n",
    "    final_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls finales de forma simple\n",
    "    print(\"\\nContando valores nulos finales...\")\n",
    "    total_final_nulls = 0\n",
    "    null_counts_final = {}\n",
    "    \n",
    "    for column_name in df.columns:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_final[column_name] = null_count\n",
    "            total_final_nulls += null_count\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls finales en {column_name}: {e}\")\n",
    "            null_counts_final[column_name] = 0\n",
    "    \n",
    "    print(f\"Total de valores nulos finales: {total_final_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # D. GUARDAR RESULTADO\n",
    "    # -------------------------------------\n",
    "    print(\"\\n--- Guardando resultado ---\")\n",
    "    \n",
    "    try:\n",
    "        # Intentar guardar con coalesce\n",
    "        df.coalesce(1).write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"compression\", \"snappy\") \\\n",
    "            .parquet(ruta_output)\n",
    "        \n",
    "        print(f\"✓ Archivo guardado exitosamente en: {ruta_output}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error con coalesce, intentando sin coalesce: {e}\")\n",
    "        try:\n",
    "            # Intentar guardar sin coalesce\n",
    "            df.write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .option(\"compression\", \"snappy\") \\\n",
    "                .parquet(ruta_output)\n",
    "            print(f\" Archivo guardado (sin coalesce) en: {ruta_output}\")\n",
    "        except Exception as e2:\n",
    "            print(f\" Error guardando archivo: {e2}\")\n",
    "            raise e2\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # E. REPORTE FINAL\n",
    "    # -------------------------------------\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"           REPORTE DE LIMPIEZA - PYSPARK\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Archivo original: {ruta_input}\")\n",
    "    print(f\"Archivo limpio: {ruta_output}\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"ESTADÍSTICAS:\")\n",
    "    print(f\"  Filas iniciales:           {initial_rows:,}\")\n",
    "    print(f\"  Filas finales:             {final_rows:,}\")\n",
    "    print(f\"  Filas eliminadas:          {initial_rows - final_rows:,}\")\n",
    "    print(f\"  Filas vacías eliminadas:   {empty_rows_removed:,}\")\n",
    "    print(f\"  Filas duplicadas elim.:    {duplicate_rows_removed:,}\")\n",
    "    print()\n",
    "    print(f\"  Columnas iniciales:        {initial_cols}\")\n",
    "    print(f\"  Columnas finales:          {final_cols}\")\n",
    "    print(f\"  Columnas eliminadas:       {len(columns_to_drop)}\")\n",
    "    print()\n",
    "    print(f\"  Valores nulos iniciales:   {total_initial_nulls:,}\")\n",
    "    print(f\"  Valores nulos finales:     {total_final_nulls:,}\")\n",
    "    print(f\"  Valores nulos limpiados:   {max(0, total_initial_nulls - total_final_nulls):,}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Mostrar detalle de nulls por columna (solo las que cambiaron)\n",
    "    print(\"CAMBIOS EN VALORES NULOS POR COLUMNA:\")\n",
    "    for column_name in df.columns:\n",
    "        initial = null_counts_initial.get(column_name, 0)\n",
    "        final = null_counts_final.get(column_name, 0)\n",
    "        if initial != final:\n",
    "            print(f\"  {column_name}: {initial} → {final}\")\n",
    "    \n",
    "    # Mostrar esquema final\n",
    "    try:\n",
    "        print(\"\\nESQUEMA FINAL:\")\n",
    "        df.printSchema()\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar el esquema: {e}\")\n",
    "    \n",
    "    # Mostrar muestra de datos\n",
    "    try:\n",
    "        print(\"MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\")\n",
    "        df.show(5, truncate=False)\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar muestra de datos: {e}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"✓ LIMPIEZA COMPLETADA EXITOSAMENTE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error durante el proceso de limpieza: {str(e)}\")\n",
    "    print(\"Detalles del error:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Cerrar Spark session\n",
    "    try:\n",
    "        spark.stop()\n",
    "        print(\"\\n Sesión de Spark cerrada\")\n",
    "    except:\n",
    "        print(\"\\n Sesión cerrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bf98bc2-a00a-4ad3-b5ec-2b2aff31cc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/17 16:00:45 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/11/17 16:00:45 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/11/17 16:00:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/11/17 16:00:45 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso de limpieza de datos...\n",
      "Archivo de entrada: /ProyectoPrincipal/tlv_ranking_propio_updated.csv\n",
      "Archivo de salida: gs://grupo01-project-sin/processed/tlv_ranking_limpio.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo leído exitosamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dimensiones iniciales: 38 filas x 9 columnas\n",
      "\n",
      "Esquema inicial:\n",
      "root\n",
      " |-- Canal: string (nullable = true)\n",
      " |-- Posicion: integer (nullable = true)\n",
      " |-- Jefe: string (nullable = true)\n",
      " |-- Ejecutivo: string (nullable = true)\n",
      " |-- Monto: double (nullable = true)\n",
      " |-- Desembolsado: double (nullable = true)\n",
      " |-- Volumen Cambiado: double (nullable = true)\n",
      " |-- Utilidad: double (nullable = true)\n",
      " |-- id_ejecutivo: integer (nullable = true)\n",
      "\n",
      "\n",
      "Contando valores nulos iniciales...\n",
      "  Canal (string): 0 nulls\n",
      "  Posicion (int): 0 nulls\n",
      "  Jefe (string): 0 nulls\n",
      "  Ejecutivo (string): 0 nulls\n",
      "  Monto (double): 0 nulls\n",
      "  Desembolsado (double): 0 nulls\n",
      "  Volumen Cambiado (double): 0 nulls\n",
      "  Utilidad (double): 0 nulls\n",
      "  id_ejecutivo (int): 0 nulls\n",
      "\n",
      "Total de valores nulos iniciales: 0\n",
      "\n",
      "--- Iniciando limpieza ---\n",
      "1. Limpiando nombres de columnas...\n",
      "  ✓ Columnas renombradas: 9 columnas\n",
      "2. Eliminando filas completamente vacías...\n",
      "  ✓ Filas vacías eliminadas: 0\n",
      "3. Eliminando duplicados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Filas duplicadas eliminadas: 0\n",
      "4. Limpiando datos por tipo de columna...\n",
      "  Procesando columna 'canal' (tipo: string)\n",
      "  Procesando columna 'posicion' (tipo: int)\n",
      "  Procesando columna 'jefe' (tipo: string)\n",
      "  Procesando columna 'ejecutivo' (tipo: string)\n",
      "  Procesando columna 'monto' (tipo: double)\n",
      "  Procesando columna 'desembolsado' (tipo: double)\n",
      "  Procesando columna 'volumen_cambiado' (tipo: double)\n",
      "  Procesando columna 'utilidad' (tipo: double)\n",
      "  Procesando columna 'id_ejecutivo' (tipo: int)\n",
      "  ✓ Procesamiento de columnas completado\n",
      "5. Verificando columnas completamente vacías...\n",
      "  ✓ No hay columnas completamente vacías\n",
      "\n",
      "Contando valores nulos finales...\n",
      "Total de valores nulos finales: 0\n",
      "\n",
      "--- Guardando resultado ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo guardado exitosamente en: gs://grupo01-project-sin/processed/tlv_ranking_limpio.parquet\n",
      "\n",
      "============================================================\n",
      "           REPORTE DE LIMPIEZA - PYSPARK\n",
      "============================================================\n",
      "Archivo original: /ProyectoPrincipal/tlv_ranking_propio_updated.csv\n",
      "Archivo limpio: gs://grupo01-project-sin/processed/tlv_ranking_limpio.parquet\n",
      "------------------------------------------------------------\n",
      "ESTADÍSTICAS:\n",
      "  Filas iniciales:           38\n",
      "  Filas finales:             38\n",
      "  Filas eliminadas:          0\n",
      "  Filas vacías eliminadas:   0\n",
      "  Filas duplicadas elim.:    0\n",
      "\n",
      "  Columnas iniciales:        9\n",
      "  Columnas finales:          9\n",
      "  Columnas eliminadas:       0\n",
      "\n",
      "  Valores nulos iniciales:   0\n",
      "  Valores nulos finales:     0\n",
      "  Valores nulos limpiados:   0\n",
      "------------------------------------------------------------\n",
      "CAMBIOS EN VALORES NULOS POR COLUMNA:\n",
      "\n",
      "ESQUEMA FINAL:\n",
      "root\n",
      " |-- canal: string (nullable = true)\n",
      " |-- posicion: integer (nullable = true)\n",
      " |-- jefe: string (nullable = true)\n",
      " |-- ejecutivo: string (nullable = true)\n",
      " |-- monto: double (nullable = true)\n",
      " |-- desembolsado: double (nullable = true)\n",
      " |-- volumen_cambiado: double (nullable = true)\n",
      " |-- utilidad: double (nullable = true)\n",
      " |-- id_ejecutivo: integer (nullable = true)\n",
      "\n",
      "MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\n",
      "+-----+--------+----------------+--------------+-------+------------+----------------+--------+------------+\n",
      "|canal|posicion|jefe            |ejecutivo     |monto  |desembolsado|volumen_cambiado|utilidad|id_ejecutivo|\n",
      "+-----+--------+----------------+--------------+-------+------------+----------------+--------+------------+\n",
      "|tlv  |4       |paula martínez  |david moreno  |9056.86|6.42        |4106.41         |1645.26 |59          |\n",
      "|tlv  |10      |paula martínez  |carmen martín |1735.83|11.21       |1179.11         |1463.77 |65          |\n",
      "|tlv  |15      |cristina jiménez|ricardo muñoz |5265.65|11.11       |4514.8          |1265.81 |70          |\n",
      "|tlv  |2       |cristina jiménez|lucía jiménez |2857.0 |3.28        |1103.17         |1712.71 |57          |\n",
      "|tlv  |3       |cristina jiménez|ricardo martín|3507.31|8.17        |2169.92         |1697.38 |58          |\n",
      "+-----+--------+----------------+--------------+-------+------------+----------------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "============================================================\n",
      "✓ LIMPIEZA COMPLETADA EXITOSAMENTE\n",
      "============================================================\n",
      "\n",
      " Sesión de Spark cerrada\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim, lower, when, lit, isnan\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, FloatType, TimestampType, DateType\n",
    "import re\n",
    "\n",
    "# Configurar Spark para Dataproc\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LimpiezaTradingCSV\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurar nivel de log para reducir output\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# RUTAS\n",
    "ruta_input = \"/ProyectoPrincipal/tlv_ranking_propio_updated.csv\" \n",
    "ruta_output = \"gs://grupo01-project-sin/processed/tlv_ranking_limpio.parquet\"\n",
    "\n",
    "print(\"Iniciando proceso de limpieza de datos...\")\n",
    "print(f\"Archivo de entrada: {ruta_input}\")\n",
    "print(f\"Archivo de salida: {ruta_output}\")\n",
    "\n",
    "try:\n",
    "    # -------------------------------------\n",
    "    # A. LECTURA DE DATOS\n",
    "    # -------------------------------------\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"multiline\", \"true\") \\\n",
    "        .option(\"escape\", '\"') \\\n",
    "        .csv(ruta_input)\n",
    "    \n",
    "    print(f\"✓ Archivo leído exitosamente\")\n",
    "    print(f\"  Dimensiones iniciales: {df.count()} filas x {len(df.columns)} columnas\")\n",
    "    \n",
    "    # Mostrar esquema inicial\n",
    "    print(\"\\nEsquema inicial:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Estadísticas iniciales\n",
    "    initial_rows = df.count()\n",
    "    initial_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls iniciales de forma simple\n",
    "    print(\"\\nContando valores nulos iniciales...\")\n",
    "    total_initial_nulls = 0\n",
    "    null_counts_initial = {}\n",
    "    \n",
    "    for column_name, data_type in df.dtypes:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_initial[column_name] = null_count\n",
    "            total_initial_nulls += null_count\n",
    "            print(f\"  {column_name} ({data_type}): {null_count} nulls\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls en {column_name}: {e}\")\n",
    "            null_counts_initial[column_name] = 0\n",
    "    \n",
    "    print(f\"\\nTotal de valores nulos iniciales: {total_initial_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # B. PROCESO DE LIMPIEZA \n",
    "    # -------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Iniciando limpieza ---\")\n",
    "    \n",
    "    # 1. LIMPIAR NOMBRES DE COLUMNAS\n",
    "    print(\"1. Limpiando nombres de columnas...\")\n",
    "    columns_before = df.columns\n",
    "    \n",
    "    # Función para limpiar nombres de columnas\n",
    "    def clean_column_name(col_name):\n",
    "        clean_name = re.sub(r'[^\\w\\s]', '', str(col_name).strip().lower())\n",
    "        clean_name = re.sub(r'\\s+', '_', clean_name)\n",
    "        return clean_name if clean_name else f\"col_{hash(col_name) % 1000}\"\n",
    "    \n",
    "    new_columns = [clean_column_name(c) for c in df.columns]\n",
    "    \n",
    "    # Verificar que no haya nombres duplicados\n",
    "    seen = set()\n",
    "    final_columns = []\n",
    "    for i, col_name in enumerate(new_columns):\n",
    "        original_name = col_name\n",
    "        counter = 1\n",
    "        while col_name in seen:\n",
    "            col_name = f\"{original_name}_{counter}\"\n",
    "            counter += 1\n",
    "        seen.add(col_name)\n",
    "        final_columns.append(col_name)\n",
    "    \n",
    "    df = df.toDF(*final_columns)\n",
    "    print(f\"  ✓ Columnas renombradas: {len(columns_before)} columnas\")\n",
    "    \n",
    "    # 2. ELIMINAR FILAS COMPLETAMENTE VACÍAS\n",
    "    print(\"2. Eliminando filas completamente vacías...\")\n",
    "    try:\n",
    "        df_before_empty = df.count()\n",
    "        df = df.na.drop(\"all\")\n",
    "        df_after_empty = df.count()\n",
    "        empty_rows_removed = df_before_empty - df_after_empty\n",
    "        print(f\"  ✓ Filas vacías eliminadas: {empty_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando filas vacías: {e}\")\n",
    "        empty_rows_removed = 0\n",
    "    \n",
    "    # 3. ELIMINAR DUPLICADOS\n",
    "    print(\"3. Eliminando duplicados...\")\n",
    "    try:\n",
    "        rows_before_dedup = df.count()\n",
    "        df = df.dropDuplicates()\n",
    "        rows_after_dedup = df.count()\n",
    "        duplicate_rows_removed = rows_before_dedup - rows_after_dedup\n",
    "        print(f\"  ✓ Filas duplicadas eliminadas: {duplicate_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando duplicados: {e}\")\n",
    "        duplicate_rows_removed = 0\n",
    "    \n",
    "    # 4. LIMPIAR DATOS POR TIPO DE COLUMNA\n",
    "    print(\"4. Limpiando datos por tipo de columna...\")\n",
    "    \n",
    "    # Valores a considerar como nulos para strings\n",
    "    invalid_vals = [\"\", \" \", \"na\", \"n/a\", \"null\", \"none\", \"nan\", \"undefined\", \"nil\", \"-\", \"NULL\", \"None\"]\n",
    "    \n",
    "    # Obtener tipos actualizados después del renombrado\n",
    "    current_dtypes = df.dtypes\n",
    "    \n",
    "    # Procesar cada columna según su tipo\n",
    "    for column_name, data_type in current_dtypes:\n",
    "        try:\n",
    "            print(f\"  Procesando columna '{column_name}' (tipo: {data_type})\")\n",
    "            \n",
    "            if data_type == \"string\":\n",
    "                # Limpiar columnas de texto\n",
    "                df = df.withColumn(column_name, \n",
    "                                 when(col(column_name).isNull(), lit(None))\n",
    "                                 .otherwise(trim(lower(col(column_name)))))\n",
    "                \n",
    "                # Reemplazar valores inválidos por null\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isin(invalid_vals), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "            elif data_type in [\"double\", \"float\"]:\n",
    "                # Limpiar columnas numéricas decimales\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isNull() | isnan(col(column_name)), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Error procesando columna {column_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"  ✓ Procesamiento de columnas completado\")\n",
    "    \n",
    "    # 5. ELIMINAR COLUMNAS COMPLETAMENTE VACÍAS (opcional)\n",
    "    print(\"5. Verificando columnas completamente vacías...\")\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    try:\n",
    "        current_row_count = df.count()\n",
    "        for column_name in df.columns:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            if null_count == current_row_count and current_row_count > 0:\n",
    "                columns_to_drop.append(column_name)\n",
    "        \n",
    "        if columns_to_drop:\n",
    "            df = df.drop(*columns_to_drop)\n",
    "            print(f\"  ✓ Columnas completamente vacías eliminadas: {columns_to_drop}\")\n",
    "        else:\n",
    "            print(f\"  ✓ No hay columnas completamente vacías\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error verificando columnas vacías: {e}\")\n",
    "        columns_to_drop = []\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # C. ESTADÍSTICAS FINALES\n",
    "    # -------------------------------------\n",
    "    final_rows = df.count()\n",
    "    final_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls finales de forma simple\n",
    "    print(\"\\nContando valores nulos finales...\")\n",
    "    total_final_nulls = 0\n",
    "    null_counts_final = {}\n",
    "    \n",
    "    for column_name in df.columns:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_final[column_name] = null_count\n",
    "            total_final_nulls += null_count\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls finales en {column_name}: {e}\")\n",
    "            null_counts_final[column_name] = 0\n",
    "    \n",
    "    print(f\"Total de valores nulos finales: {total_final_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # D. GUARDAR RESULTADO\n",
    "    # -------------------------------------\n",
    "    print(\"\\n--- Guardando resultado ---\")\n",
    "    \n",
    "    try:\n",
    "        # Intentar guardar con coalesce\n",
    "        df.coalesce(1).write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"compression\", \"snappy\") \\\n",
    "            .parquet(ruta_output)\n",
    "        \n",
    "        print(f\"✓ Archivo guardado exitosamente en: {ruta_output}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error con coalesce, intentando sin coalesce: {e}\")\n",
    "        try:\n",
    "            # Intentar guardar sin coalesce\n",
    "            df.write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .option(\"compression\", \"snappy\") \\\n",
    "                .parquet(ruta_output)\n",
    "            print(f\" Archivo guardado (sin coalesce) en: {ruta_output}\")\n",
    "        except Exception as e2:\n",
    "            print(f\" Error guardando archivo: {e2}\")\n",
    "            raise e2\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # E. REPORTE FINAL\n",
    "    # -------------------------------------\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"           REPORTE DE LIMPIEZA - PYSPARK\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Archivo original: {ruta_input}\")\n",
    "    print(f\"Archivo limpio: {ruta_output}\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"ESTADÍSTICAS:\")\n",
    "    print(f\"  Filas iniciales:           {initial_rows:,}\")\n",
    "    print(f\"  Filas finales:             {final_rows:,}\")\n",
    "    print(f\"  Filas eliminadas:          {initial_rows - final_rows:,}\")\n",
    "    print(f\"  Filas vacías eliminadas:   {empty_rows_removed:,}\")\n",
    "    print(f\"  Filas duplicadas elim.:    {duplicate_rows_removed:,}\")\n",
    "    print()\n",
    "    print(f\"  Columnas iniciales:        {initial_cols}\")\n",
    "    print(f\"  Columnas finales:          {final_cols}\")\n",
    "    print(f\"  Columnas eliminadas:       {len(columns_to_drop)}\")\n",
    "    print()\n",
    "    print(f\"  Valores nulos iniciales:   {total_initial_nulls:,}\")\n",
    "    print(f\"  Valores nulos finales:     {total_final_nulls:,}\")\n",
    "    print(f\"  Valores nulos limpiados:   {max(0, total_initial_nulls - total_final_nulls):,}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Mostrar detalle de nulls por columna (solo las que cambiaron)\n",
    "    print(\"CAMBIOS EN VALORES NULOS POR COLUMNA:\")\n",
    "    for column_name in df.columns:\n",
    "        initial = null_counts_initial.get(column_name, 0)\n",
    "        final = null_counts_final.get(column_name, 0)\n",
    "        if initial != final:\n",
    "            print(f\"  {column_name}: {initial} → {final}\")\n",
    "    \n",
    "    # Mostrar esquema final\n",
    "    try:\n",
    "        print(\"\\nESQUEMA FINAL:\")\n",
    "        df.printSchema()\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar el esquema: {e}\")\n",
    "    \n",
    "    # Mostrar muestra de datos\n",
    "    try:\n",
    "        print(\"MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\")\n",
    "        df.show(5, truncate=False)\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar muestra de datos: {e}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"✓ LIMPIEZA COMPLETADA EXITOSAMENTE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error durante el proceso de limpieza: {str(e)}\")\n",
    "    print(\"Detalles del error:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Cerrar Spark session\n",
    "    try:\n",
    "        spark.stop()\n",
    "        print(\"\\n Sesión de Spark cerrada\")\n",
    "    except:\n",
    "        print(\"\\n Sesión cerrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60efd706-0342-4e82-9cb4-e35319ae8c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/17 16:50:43 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso de limpieza de datos...\n",
      "Archivo de entrada: /ProyectoPrincipal/virtual_ranking_propio_updated.csv\n",
      "Archivo de salida: gs://grupo01-project-sin/processed/virtual_ranking_limpio.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo leído exitosamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dimensiones iniciales: 25 filas x 9 columnas\n",
      "\n",
      "Esquema inicial:\n",
      "root\n",
      " |-- Canal: string (nullable = true)\n",
      " |-- Posicion: integer (nullable = true)\n",
      " |-- Jefe: string (nullable = true)\n",
      " |-- Ejecutivo: string (nullable = true)\n",
      " |-- Monto: double (nullable = true)\n",
      " |-- Desembolsado: double (nullable = true)\n",
      " |-- Volumen Cambiado: double (nullable = true)\n",
      " |-- Utilidad: double (nullable = true)\n",
      " |-- id_ejecutivo: integer (nullable = true)\n",
      "\n",
      "\n",
      "Contando valores nulos iniciales...\n",
      "  Canal (string): 0 nulls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Posicion (int): 0 nulls\n",
      "  Jefe (string): 0 nulls\n",
      "  Ejecutivo (string): 0 nulls\n",
      "  Monto (double): 0 nulls\n",
      "  Desembolsado (double): 0 nulls\n",
      "  Volumen Cambiado (double): 0 nulls\n",
      "  Utilidad (double): 0 nulls\n",
      "  id_ejecutivo (int): 0 nulls\n",
      "\n",
      "Total de valores nulos iniciales: 0\n",
      "\n",
      "--- Iniciando limpieza ---\n",
      "1. Limpiando nombres de columnas...\n",
      "  ✓ Columnas renombradas: 9 columnas\n",
      "2. Eliminando filas completamente vacías...\n",
      "  ✓ Filas vacías eliminadas: 0\n",
      "3. Eliminando duplicados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Filas duplicadas eliminadas: 0\n",
      "4. Limpiando datos por tipo de columna...\n",
      "  Procesando columna 'canal' (tipo: string)\n",
      "  Procesando columna 'posicion' (tipo: int)\n",
      "  Procesando columna 'jefe' (tipo: string)\n",
      "  Procesando columna 'ejecutivo' (tipo: string)\n",
      "  Procesando columna 'monto' (tipo: double)\n",
      "  Procesando columna 'desembolsado' (tipo: double)\n",
      "  Procesando columna 'volumen_cambiado' (tipo: double)\n",
      "  Procesando columna 'utilidad' (tipo: double)\n",
      "  Procesando columna 'id_ejecutivo' (tipo: int)\n",
      "  ✓ Procesamiento de columnas completado\n",
      "5. Verificando columnas completamente vacías...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ No hay columnas completamente vacías\n",
      "\n",
      "Contando valores nulos finales...\n",
      "Total de valores nulos finales: 0\n",
      "\n",
      "--- Guardando resultado ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo guardado exitosamente en: gs://grupo01-project-sin/processed/virtual_ranking_limpio.parquet\n",
      "\n",
      "============================================================\n",
      "           REPORTE DE LIMPIEZA - PYSPARK\n",
      "============================================================\n",
      "Archivo original: /ProyectoPrincipal/virtual_ranking_propio_updated.csv\n",
      "Archivo limpio: gs://grupo01-project-sin/processed/virtual_ranking_limpio.parquet\n",
      "------------------------------------------------------------\n",
      "ESTADÍSTICAS:\n",
      "  Filas iniciales:           25\n",
      "  Filas finales:             25\n",
      "  Filas eliminadas:          0\n",
      "  Filas vacías eliminadas:   0\n",
      "  Filas duplicadas elim.:    0\n",
      "\n",
      "  Columnas iniciales:        9\n",
      "  Columnas finales:          9\n",
      "  Columnas eliminadas:       0\n",
      "\n",
      "  Valores nulos iniciales:   0\n",
      "  Valores nulos finales:     0\n",
      "  Valores nulos limpiados:   0\n",
      "------------------------------------------------------------\n",
      "CAMBIOS EN VALORES NULOS POR COLUMNA:\n",
      "\n",
      "ESQUEMA FINAL:\n",
      "root\n",
      " |-- canal: string (nullable = true)\n",
      " |-- posicion: integer (nullable = true)\n",
      " |-- jefe: string (nullable = true)\n",
      " |-- ejecutivo: string (nullable = true)\n",
      " |-- monto: double (nullable = true)\n",
      " |-- desembolsado: double (nullable = true)\n",
      " |-- volumen_cambiado: double (nullable = true)\n",
      " |-- utilidad: double (nullable = true)\n",
      " |-- id_ejecutivo: integer (nullable = true)\n",
      "\n",
      "MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\n",
      "+-------+--------+----------------+--------------+-------+------------+----------------+--------+------------+\n",
      "|canal  |posicion|jefe            |ejecutivo     |monto  |desembolsado|volumen_cambiado|utilidad|id_ejecutivo|\n",
      "+-------+--------+----------------+--------------+-------+------------+----------------+--------+------------+\n",
      "|virtual|18      |andrea rodríguez|carlos jiménez|5858.75|1.44        |4358.54         |619.29  |111         |\n",
      "|virtual|19      |andrea rodríguez|david alonso  |5520.6 |16.01       |2248.17         |601.3   |112         |\n",
      "|virtual|24      |andrea rodríguez|ana navarro   |9979.23|19.22       |1408.76         |367.99  |117         |\n",
      "|virtual|3       |ana jiménez     |carmen sánchez|6391.26|18.3        |1466.66         |1535.62 |96          |\n",
      "|virtual|17      |ana jiménez     |manuel álvarez|7362.82|5.32        |1175.71         |621.96  |110         |\n",
      "+-------+--------+----------------+--------------+-------+------------+----------------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "============================================================\n",
      "✓ LIMPIEZA COMPLETADA EXITOSAMENTE\n",
      "============================================================\n",
      "\n",
      " Sesión de Spark cerrada\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim, lower, when, lit, isnan\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, FloatType, TimestampType, DateType\n",
    "import re\n",
    "\n",
    "# Configurar Spark para Dataproc\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LimpiezaTradingCSV\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurar nivel de log para reducir output\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# RUTAS\n",
    "ruta_input = \"/ProyectoPrincipal/virtual_ranking_propio_updated.csv\" \n",
    "ruta_output = \"gs://grupo01-project-sin/processed/virtual_ranking_limpio.parquet\"\n",
    "\n",
    "print(\"Iniciando proceso de limpieza de datos...\")\n",
    "print(f\"Archivo de entrada: {ruta_input}\")\n",
    "print(f\"Archivo de salida: {ruta_output}\")\n",
    "\n",
    "try:\n",
    "    # -------------------------------------\n",
    "    # A. LECTURA DE DATOS\n",
    "    # -------------------------------------\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"multiline\", \"true\") \\\n",
    "        .option(\"escape\", '\"') \\\n",
    "        .csv(ruta_input)\n",
    "    \n",
    "    print(f\"✓ Archivo leído exitosamente\")\n",
    "    print(f\"  Dimensiones iniciales: {df.count()} filas x {len(df.columns)} columnas\")\n",
    "    \n",
    "    # Mostrar esquema inicial\n",
    "    print(\"\\nEsquema inicial:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Estadísticas iniciales\n",
    "    initial_rows = df.count()\n",
    "    initial_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls iniciales de forma simple\n",
    "    print(\"\\nContando valores nulos iniciales...\")\n",
    "    total_initial_nulls = 0\n",
    "    null_counts_initial = {}\n",
    "    \n",
    "    for column_name, data_type in df.dtypes:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_initial[column_name] = null_count\n",
    "            total_initial_nulls += null_count\n",
    "            print(f\"  {column_name} ({data_type}): {null_count} nulls\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls en {column_name}: {e}\")\n",
    "            null_counts_initial[column_name] = 0\n",
    "    \n",
    "    print(f\"\\nTotal de valores nulos iniciales: {total_initial_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # B. PROCESO DE LIMPIEZA \n",
    "    # -------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Iniciando limpieza ---\")\n",
    "    \n",
    "    # 1. LIMPIAR NOMBRES DE COLUMNAS\n",
    "    print(\"1. Limpiando nombres de columnas...\")\n",
    "    columns_before = df.columns\n",
    "    \n",
    "    # Función para limpiar nombres de columnas\n",
    "    def clean_column_name(col_name):\n",
    "        clean_name = re.sub(r'[^\\w\\s]', '', str(col_name).strip().lower())\n",
    "        clean_name = re.sub(r'\\s+', '_', clean_name)\n",
    "        return clean_name if clean_name else f\"col_{hash(col_name) % 1000}\"\n",
    "    \n",
    "    new_columns = [clean_column_name(c) for c in df.columns]\n",
    "    \n",
    "    # Verificar que no haya nombres duplicados\n",
    "    seen = set()\n",
    "    final_columns = []\n",
    "    for i, col_name in enumerate(new_columns):\n",
    "        original_name = col_name\n",
    "        counter = 1\n",
    "        while col_name in seen:\n",
    "            col_name = f\"{original_name}_{counter}\"\n",
    "            counter += 1\n",
    "        seen.add(col_name)\n",
    "        final_columns.append(col_name)\n",
    "    \n",
    "    df = df.toDF(*final_columns)\n",
    "    print(f\"  ✓ Columnas renombradas: {len(columns_before)} columnas\")\n",
    "    \n",
    "    # 2. ELIMINAR FILAS COMPLETAMENTE VACÍAS\n",
    "    print(\"2. Eliminando filas completamente vacías...\")\n",
    "    try:\n",
    "        df_before_empty = df.count()\n",
    "        df = df.na.drop(\"all\")\n",
    "        df_after_empty = df.count()\n",
    "        empty_rows_removed = df_before_empty - df_after_empty\n",
    "        print(f\"  ✓ Filas vacías eliminadas: {empty_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando filas vacías: {e}\")\n",
    "        empty_rows_removed = 0\n",
    "    \n",
    "    # 3. ELIMINAR DUPLICADOS\n",
    "    print(\"3. Eliminando duplicados...\")\n",
    "    try:\n",
    "        rows_before_dedup = df.count()\n",
    "        df = df.dropDuplicates()\n",
    "        rows_after_dedup = df.count()\n",
    "        duplicate_rows_removed = rows_before_dedup - rows_after_dedup\n",
    "        print(f\"  ✓ Filas duplicadas eliminadas: {duplicate_rows_removed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error eliminando duplicados: {e}\")\n",
    "        duplicate_rows_removed = 0\n",
    "    \n",
    "    # 4. LIMPIAR DATOS POR TIPO DE COLUMNA\n",
    "    print(\"4. Limpiando datos por tipo de columna...\")\n",
    "    \n",
    "    # Valores a considerar como nulos para strings\n",
    "    invalid_vals = [\"\", \" \", \"na\", \"n/a\", \"null\", \"none\", \"nan\", \"undefined\", \"nil\", \"-\", \"NULL\", \"None\"]\n",
    "    \n",
    "    # Obtener tipos actualizados después del renombrado\n",
    "    current_dtypes = df.dtypes\n",
    "    \n",
    "    # Procesar cada columna según su tipo\n",
    "    for column_name, data_type in current_dtypes:\n",
    "        try:\n",
    "            print(f\"  Procesando columna '{column_name}' (tipo: {data_type})\")\n",
    "            \n",
    "            if data_type == \"string\":\n",
    "                # Limpiar columnas de texto\n",
    "                df = df.withColumn(column_name, \n",
    "                                 when(col(column_name).isNull(), lit(None))\n",
    "                                 .otherwise(trim(lower(col(column_name)))))\n",
    "                \n",
    "                # Reemplazar valores inválidos por null\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isin(invalid_vals), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "            elif data_type in [\"double\", \"float\"]:\n",
    "                # Limpiar columnas numéricas decimales\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    when(col(column_name).isNull() | isnan(col(column_name)), lit(None))\n",
    "                    .otherwise(col(column_name))\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Error procesando columna {column_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"  ✓ Procesamiento de columnas completado\")\n",
    "    \n",
    "    # 5. ELIMINAR COLUMNAS COMPLETAMENTE VACÍAS (opcional)\n",
    "    print(\"5. Verificando columnas completamente vacías...\")\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    try:\n",
    "        current_row_count = df.count()\n",
    "        for column_name in df.columns:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            if null_count == current_row_count and current_row_count > 0:\n",
    "                columns_to_drop.append(column_name)\n",
    "        \n",
    "        if columns_to_drop:\n",
    "            df = df.drop(*columns_to_drop)\n",
    "            print(f\"  ✓ Columnas completamente vacías eliminadas: {columns_to_drop}\")\n",
    "        else:\n",
    "            print(f\"  ✓ No hay columnas completamente vacías\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error verificando columnas vacías: {e}\")\n",
    "        columns_to_drop = []\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # C. ESTADÍSTICAS FINALES\n",
    "    # -------------------------------------\n",
    "    final_rows = df.count()\n",
    "    final_cols = len(df.columns)\n",
    "    \n",
    "    # Contar nulls finales de forma simple\n",
    "    print(\"\\nContando valores nulos finales...\")\n",
    "    total_final_nulls = 0\n",
    "    null_counts_final = {}\n",
    "    \n",
    "    for column_name in df.columns:\n",
    "        try:\n",
    "            null_count = df.filter(col(column_name).isNull()).count()\n",
    "            null_counts_final[column_name] = null_count\n",
    "            total_final_nulls += null_count\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error contando nulls finales en {column_name}: {e}\")\n",
    "            null_counts_final[column_name] = 0\n",
    "    \n",
    "    print(f\"Total de valores nulos finales: {total_final_nulls}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # D. GUARDAR RESULTADO\n",
    "    # -------------------------------------\n",
    "    print(\"\\n--- Guardando resultado ---\")\n",
    "    \n",
    "    try:\n",
    "        # Intentar guardar con coalesce\n",
    "        df.coalesce(1).write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"compression\", \"snappy\") \\\n",
    "            .parquet(ruta_output)\n",
    "        \n",
    "        print(f\"✓ Archivo guardado exitosamente en: {ruta_output}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error con coalesce, intentando sin coalesce: {e}\")\n",
    "        try:\n",
    "            # Intentar guardar sin coalesce\n",
    "            df.write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .option(\"compression\", \"snappy\") \\\n",
    "                .parquet(ruta_output)\n",
    "            print(f\" Archivo guardado (sin coalesce) en: {ruta_output}\")\n",
    "        except Exception as e2:\n",
    "            print(f\" Error guardando archivo: {e2}\")\n",
    "            raise e2\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # E. REPORTE FINAL\n",
    "    # -------------------------------------\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"           REPORTE DE LIMPIEZA - PYSPARK\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Archivo original: {ruta_input}\")\n",
    "    print(f\"Archivo limpio: {ruta_output}\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"ESTADÍSTICAS:\")\n",
    "    print(f\"  Filas iniciales:           {initial_rows:,}\")\n",
    "    print(f\"  Filas finales:             {final_rows:,}\")\n",
    "    print(f\"  Filas eliminadas:          {initial_rows - final_rows:,}\")\n",
    "    print(f\"  Filas vacías eliminadas:   {empty_rows_removed:,}\")\n",
    "    print(f\"  Filas duplicadas elim.:    {duplicate_rows_removed:,}\")\n",
    "    print()\n",
    "    print(f\"  Columnas iniciales:        {initial_cols}\")\n",
    "    print(f\"  Columnas finales:          {final_cols}\")\n",
    "    print(f\"  Columnas eliminadas:       {len(columns_to_drop)}\")\n",
    "    print()\n",
    "    print(f\"  Valores nulos iniciales:   {total_initial_nulls:,}\")\n",
    "    print(f\"  Valores nulos finales:     {total_final_nulls:,}\")\n",
    "    print(f\"  Valores nulos limpiados:   {max(0, total_initial_nulls - total_final_nulls):,}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Mostrar detalle de nulls por columna (solo las que cambiaron)\n",
    "    print(\"CAMBIOS EN VALORES NULOS POR COLUMNA:\")\n",
    "    for column_name in df.columns:\n",
    "        initial = null_counts_initial.get(column_name, 0)\n",
    "        final = null_counts_final.get(column_name, 0)\n",
    "        if initial != final:\n",
    "            print(f\"  {column_name}: {initial} → {final}\")\n",
    "    \n",
    "    # Mostrar esquema final\n",
    "    try:\n",
    "        print(\"\\nESQUEMA FINAL:\")\n",
    "        df.printSchema()\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar el esquema: {e}\")\n",
    "    \n",
    "    # Mostrar muestra de datos\n",
    "    try:\n",
    "        print(\"MUESTRA DE DATOS LIMPIOS (primeras 5 filas):\")\n",
    "        df.show(5, truncate=False)\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo mostrar muestra de datos: {e}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"✓ LIMPIEZA COMPLETADA EXITOSAMENTE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error durante el proceso de limpieza: {str(e)}\")\n",
    "    print(\"Detalles del error:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Cerrar Spark session\n",
    "    try:\n",
    "        spark.stop()\n",
    "        print(\"\\n Sesión de Spark cerrada\")\n",
    "    except:\n",
    "        print(\"\\n Sesión cerrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f650f-f089-441d-a967-5740f15662c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
