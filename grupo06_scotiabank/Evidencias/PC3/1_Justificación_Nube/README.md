# üè¶ 1. Justificaci√≥n del Uso de la Nube

### *Comparaci√≥n t√©cnica y financiera entre AWS, Azure y GCP*

## 1.1 Recordatorio

El proyecto planteado por el equipo, consiste en la construcci√≥n de un flujo completo de Inteligencia de Negocios: web scraping, ETL, arquitectura Medallion (Bronce-Plata-Oro), procesamiento PySpark, almacenamiento anal√≠tico y visualizaci√≥n final en Power BI.
Para migrar este proyecto a la nube, se evaluaron **AWS**, **Azure** y **Google Cloud Platform (GCP)** considerandolos algunas caracteristicas que tiene el proyecto:

* Dataset reducido (~1GB).
* Adopci√≥n de una arquitectura Medallion.
* Preferencia por servicios **serverless** para evitar mantenimiento.
* Curva de aprendizaje manejable.
* Seguridad para un entorno bancario.

---

## 1.2 Criterios de evaluaci√≥n

Los criterios aplicados son:

1. **Seguridad y cumplimiento normativo**
2. **Escalabilidad y elasticidad operativa**
3. **Estructura de costos y modelos de pricing**
4. **Ecosistema de BI**
5. **Redundancia, resiliencia y continuidad operativa**
6. **Capacidades de red (latencia, ancho de banda)**
7. **Soporte para cargas batch**

---

## 1.3 Comparaci√≥n t√©cnica entre AWS, Azure y GCP

A continuaci√≥n se compararan en profundidad cada uno de los criterios aplicados para la evaluaci√≥n de AWS, Azure y Google Cloud Platform (GCP).

### 1.3.1 Seguridad y cumplimiento normativo

La seguridad en entornos cloud se analiza desde tres puntos: controles de identidad, capacidades de protecci√≥n de datos y portafolio de cumplimiento normativo.
Para entornos bancarios, estos aspectos deben alinearse con normativas como PCI DSS, ISO 27001, SOC 2 para temas de seguridad.

| Aspecto | AWS | Azure | GCP |
|---------|-----|-------|-----|
| **Certificaciones de cumplimiento** | 143 est√°ndares (ISO 27001, SOC 1/2/3, PCI DSS Level 1, HIPAA) | 116 est√°ndares (ISO 27001, SOC 1/2/3, PCI DSS, ENS High) | 98 est√°ndares (ISO 27001, SOC 1/2/3, PCI DSS Level 1) |
| **Cifrado por defecto** | Opcional (debe habilitarse manualmente en S3, RDS, etc.) | Opcional (debe configurarse en Storage, SQL Database) | **Autom√°tico en todos los servicios sin configuraci√≥n** |
| **Modelo Zero Trust** | IAM + AWS Organizations + GuardDuty | Microsoft Entra ID + Conditional Access + Defender | **BeyondCorp (implementaci√≥n nativa desde 2011)** |
| **Gesti√≥n de claves** | AWS KMS (control granular por regi√≥n) | Azure Key Vault (integraci√≥n con HSM) | Cloud KMS + **Cloud HSM certificado FIPS 140-2 Nivel 3** |
| **Auditor√≠a y logging** | CloudTrail (registro de API calls) | Azure Monitor + Log Analytics | **Cloud Audit Logs (habilitado por defecto, inmutable)** |
| **DLP nativo** | Amazon Macie (ML para datos sensibles en S3) | Microsoft Purview (integrado con M365) | **Cloud DLP (detecci√≥n de 150+ tipos de datos sensibles)** |

**Requisitos de seguridad para proyecto:**

| Requisito | AWS | Azure | GCP |
|-----------|-----|-------|-----|
| Cifrado autom√°tico | ‚ùå Manual | ‚ùå Manual | ‚úÖ **Autom√°tico** |
| Auditor√≠a por defecto | ‚ö†Ô∏è Debe configurarse | ‚ö†Ô∏è Debe configurarse | ‚úÖ **Inmutable y autom√°tico** |
| Complejidad de configuraci√≥n | ‚ö†Ô∏è Alta | ‚ö†Ô∏è Media-Alta | ‚úÖ **M√≠nima** |


**GCP satisface todos los requisitos de seguridad bancaria con el menor overhead operativo**, permitiendo enfocarnos en la arquitectura de datos en lugar de configuraci√≥n de controles de seguridad.


### 1.3.2 Escalabilidad y elasticidad

La escalabilidad eval√∫a la capacidad de ajustar recursos autom√°ticamente seg√∫n la demanda, mientras que la elasticidad mide qu√© tan r√°pido y eficiente es ese ajuste. En funci√≥n de nuestro proyecto, se requiere escalamiento horizontal autom√°tico sin intervenci√≥n manual.

| Aspecto | AWS | Azure | GCP |
|---------|-----|-------|-----|
| **Procesamiento Spark** | EMR con Auto Scaling (escala por nodos, requiere configuraci√≥n de m√©tricas) | Synapse Spark Pools (escalamiento manual o autom√°tico con warmup) | **Dataproc Serverless (escala de 0 a N workers autom√°ticamente)** |
| **Tiempo de escalamiento** | 5-10 minutos (provisionar nuevos nodos) | 3-8 minutos (activar pool + warmup) | **< 1 minuto (sin cl√∫steres permanentes)** |
| **Modelo de escalamiento** | Basado en m√©tricas de CloudWatch (CPU, memoria, custom) | Basado en carga de trabajo o programado | **Completamente autom√°tico basado en demanda** |
| **Almacenamiento anal√≠tico** | Redshift: escala mediante resize (minutos a horas de downtime) | Synapse SQL: escala DWUs (pausable manualmente) | **BigQuery: escalamiento transparente sin gesti√≥n** |
| **Escalamiento a cero** | EMR requiere al menos 1 nodo master activo | Synapse puede pausarse pero requiere acci√≥n manual | **Dataproc Serverless escala a 0 autom√°ticamente** |
| **Orquestaci√≥n batch** | Step Functions (escala autom√°ticamente) | Azure Data Factory (escala por Integration Runtime) | **Cloud Composer (Airflow administrado, escala autom√°ticamente)** |
| **Granularidad de escalamiento** | Por instancia completa (m√≠nimo 1 EC2) | Por unidad de procesamiento (vCore, DWU) | **Por vCPU-segundo en Dataproc, por slot en BigQuery** |


**Requisitos de escalabilidad para el proyecto**

| Requisito | AWS | Azure | GCP |
|-----------|-----|-------|-----|
| Escalamiento sin gesti√≥n de cl√∫steres | ‚ùå Requiere EMR | ‚ùå Requiere Spark Pools | ‚úÖ **Dataproc Serverless** |
| Escala a cero entre ejecuciones batch | ‚ùå No (nodo master permanente) | ‚ö†Ô∏è Manual | ‚úÖ **Autom√°tico** |
| Tiempo de inicio < 2 minutos | ‚ùå 5-10 min | ‚ö†Ô∏è 3-8 min | ‚úÖ **< 1 min** |
| Almacenamiento anal√≠tico sin gesti√≥n | ‚ö†Ô∏è Redshift Serverless (limitado) | ‚ö†Ô∏è Synapse (requiere configuraci√≥n) | ‚úÖ **BigQuery (completamente autom√°tico)** |
| Facturaci√≥n por uso real | ‚ùå Factura por hora de cl√∫ster | ‚ö†Ô∏è Factura por pool activo | ‚úÖ **Por vCPU-segundo real** |


**Para el proyecto con ejecuciones batch y dataset reducido**, GCP ofrece la elasticidad m√°s eficiente.



### 1.3.3 Costos y modelo de pricing

Se eval√∫a un aprocimado del costo total de operaci√≥n (TCO) considerando procesamiento , almacenamiento, consultas anal√≠ticas y servicios de orquestaci√≥n para **1-2 ejecuciones mensuales de ETL**.

| Componente | AWS | Azure | GCP |
|------------|-----|-------|-----|
| **Almacenamiento objeto (Bronce)** | S3 Standard: $0.023/GB-mes | ADLS Gen2: $0.0208/GB-mes | Cloud Storage Standard: **$0.020/GB-mes** |
| **Almacenamiento anal√≠tico (Oro)** | Redshift Serverless: $0.375/RPU-hora (m√≠nimo 8 RPUs = **$3/hora**) | Synapse SQL: $1.20/DWU-hora (m√≠nimo 100 DWUs = **$120/hora**) | BigQuery: **$5/TB consultado** (storage: $0.020/GB-mes) |
| **Orquestaci√≥n ETL** | Step Functions: $0.025/1000 transiciones + Lambda ($0.20/mill√≥n requests) | Data Factory: **$1/1000 pipeline runs** | Cloud Scheduler: **$0.10/job-mes** (3 jobs gratis) |
| **Transferencia de datos** | $0.09/GB salida internet | $0.087/GB salida internet | **$0.12/GB salida internet** (primeros 1GB/mes gratis) |
| **Modelo de facturaci√≥n** | Por tiempo de recurso activo | Por unidad de procesamiento-hora | **Por uso real (pay-per-query)** |


##### **Comparaci√≥n de costos por componente clave**

**Procesamiento Spark (por job de 20 minutos)**

| Proveedor | Configuraci√≥n | Costo por Job | Costo 2 Jobs/Mes |
|-----------|---------------|---------------|-------------------|
| **AWS EMR** | 2 nodos m5.xlarge | **$0.19** | **$0.38** |
| **Azure Synapse** | 4 vCores Spark Pool | **$0.58** | **$1.16** |
| **GCP Dataproc Serverless** | 4 vCPUs (escalamiento autom√°tico) | **$0.075** | **$0.15** |

GCP es 2.5x m√°s barato que AWS y 7.7x m√°s barato que Azure en procesamiento Spark.

**Almacenamiento y consultas anal√≠ticas (uso mensual real)**

| Proveedor | Modelo | Costo 25 Queries (150 MB promedio cada una) | Observaciones |
|-----------|--------|----------------------------------------------|---------------|
| **AWS Redshift** | Serverless (factura por RPU-hora) | **$6/mes** (estimado 2h uso espor√°dico) | Cobra por tiempo de endpoint activo aunque no se use |
| **Azure Synapse SQL** | Serverless Pool | **$0.02/mes** ($5/TB escaneado √ó 0.00375 TB) | Opci√≥n viable y econ√≥mica |
| **GCP BigQuery** | Pay-per-query | **$0.02/mes** (3.75 GB escaneados) | **Dentro del free tier (1 TB/mes gratis)** = **$0** |

BigQuery es efectivamente GRATIS para este proyecto (3.75 GB << 1 TB l√≠mite), mientras AWS Redshift cuesta $6/mes por mantener endpoint.


**Ventaja clave: Frecuencia baja de ejecuci√≥n**

Con solo **1-2 ejecuciones mensuales**, el impacto de costos es m√≠nimo en las tres plataformas, pero GCP mantiene ventajas estructurales:

| Aspecto | AWS | Azure | GCP |
|---------|-----|-------|-----|
| **Costo por ejecuci√≥n espor√°dica** | EMR cobra por cl√∫ster completo aunque se use 20 min | Synapse cobra por pool aunque se use poco | **Dataproc solo cobra por tiempo real de procesamiento** |
| **Penalizaci√≥n por uso infrecuente** | ‚ö†Ô∏è Redshift mantiene costos base | ‚úÖ Synapse Serverless eficiente | ‚úÖ **BigQuery sin costos fijos** |
| **Sostenibilidad a largo plazo** | ‚ö†Ô∏è Costos permanentes aunque uso sea m√≠nimo | ‚úÖ Modelo viable | ‚úÖ **Gratis indefinidamente dentro de l√≠mites** |



### 1.3.4 Ecosistema de Business Intelligence

El ecosistema de BI eval√∫a la capacidad de cada proveedor para soportar el flujo completo: ingesta de datos, transformaci√≥n ETL, arquitectura Medallion (Bronce-Plata-Oro), procesamiento PySpark y visualizaci√≥n final en Power BI. Se prioriza integraci√≥n nativa, simplicidad operativa y compatibilidad con herramientas del proyecto.


| Componente | AWS | Azure | GCP |
|------------|-----|-------|-----|
| **Ingesta/Web Scraping** | Lambda + EventBridge | Azure Functions + Logic Apps | **Cloud Functions + Cloud Scheduler** |
| **Almacenamiento Bronce (raw data)** | S3 (object storage) | ADLS Gen2 (object storage) | **Cloud Storage (object storage)** |
| **Procesamiento ETL (Plata)** | AWS Glue o EMR (PySpark) | Azure Data Factory + Synapse Spark | **Dataproc Serverless (PySpark) + Dataflow** |
| **Almacenamiento anal√≠tico (Oro)** | Redshift / Redshift Spectrum | Synapse Analytics (SQL Pools) | **BigQuery (columnar, serverless)** |
| **Orquestaci√≥n de pipelines** | Step Functions + MWAA (Airflow) | Data Factory + Synapse Pipelines | **Cloud Composer (Airflow administrado) / Cloud Scheduler** |
| **Integraci√≥n con Power BI** | Conector gen√©rico ODBC/JDBC (requiere configuraci√≥n) |**Conector nativo certificado** (integraci√≥n profunda) |*Conector oficial BigQuery y Power BI(DirectQuery) |
| **Notebooks interactivos** | EMR Notebooks / SageMaker | Synapse Notebooks (integrado) | **Vertex AI Workbench / Dataproc Notebooks** |
| **Transformaci√≥n SQL** | Athena (query S3 directamente) | Synapse SQL Serverless | **BigQuery (SQL est√°ndar, sin infraestructura)** |
| **Visualizaci√≥n nativa** | QuickSight (b√°sica, adicional) | Power BI (ecosistema Microsoft) | Looker / Looker Studio (Data Studio) |


**Requisitos del ecosistema BI para el proyecto**

| Requisito | AWS | Azure | GCP |
|-----------|-----|-------|-----|
| Soporte PySpark sin gesti√≥n cl√∫steres | ‚ùå EMR requiere cl√∫steres | ‚ùå Synapse requiere pools | ‚úÖ **Dataproc Serverless** |
| Arquitectura Medallion | ‚úÖ S3 + EMR/Glue + Redshift/Athena | ‚úÖ ADLS + Synapse Spark + Synapse SQL | ‚úÖ **Cloud Storage + Dataproc + BigQuery** |
| SQL est√°ndar (ANSI compatible) | ‚ö†Ô∏è PostgreSQL-like | ‚ö†Ô∏è T-SQL (Microsoft) | ‚úÖ **ANSI SQL:2011 completo** |
| Notebooks interactivos para desarrollo | ‚úÖ EMR Notebooks / SageMaker | ‚úÖ Synapse Notebooks integrados | ‚úÖ **Vertex AI Workbench / Dataproc Notebooks** |
| Orquestaci√≥n programada (cron-like) | ‚ö†Ô∏è EventBridge + Step Functions | ‚ö†Ô∏è Data Factory triggers | ‚úÖ **Cloud Scheduler (sintaxis cron nativa)** |
| Costo de infraestructura BI | üî¥ Alto (cl√∫steres + warehouse) | üü° Medio (pools + SQL) | ‚úÖ **Bajo (serverless completo)** |

**GCP ofrece el ecosistema BI m√°s eficiente para este proyecto**: combina procesamiento serverless (Dataproc), almacenamiento anal√≠tico de alto rendimiento (BigQuery) e integraci√≥n directa con Power BI, todo con complejidad operativa m√≠nima y costo cero dentro del free tier.



### 1.3.5 Redundancia, resiliencia y continuidad operativa

La redundancia eval√∫a la capacidad de recuperaci√≥n ante fallos de hardware o zonas completas, mientras que la resiliencia mide la disponibilidad continua del servicio. Para un proyecto BI bancario, se requiere alta disponibilidad de datos y recuperaci√≥n ante desastres, aunque con tolerancia a interrupciones breves dado el car√°cter batch del procesamiento.


**Comparaci√≥n de arquitectura de disponibilidad**

| Aspecto | AWS | Azure | GCP |
|---------|-----|-------|-----|
| **Regiones globales** | **33 regiones** (diciembre 2024) | 60+ regiones | 40+ regiones |
| **Zonas de disponibilidad (AZs)** |**105 AZs** (3+ por regi√≥n) | 3+ por regi√≥n (menor cantidad total) | **3+ por regi√≥n** (Google Global Network) |
| **Regiones en Sudam√©rica** | 1 (S√£o Paulo, Brasil) | 1 (Brazil South) | **2 (S√£o Paulo + Santiago de Chile)** |
| **Distancia desde Lima** | S√£o Paulo: ~3,150 km | Brazil South: ~3,150 km | **Santiago: ~2,200 km** (30% m√°s cerca) |
| **SLA de almacenamiento** | S3 Standard: 99.99% disponibilidad | ADLS Gen2: 99.9% disponibilidad | Cloud Storage: **99.95% disponibilidad** |
| **SLA de data warehouse** | Redshift: 99.9% (Multi-AZ) | Synapse: 99.9% | BigQuery: **99.99% (autom√°tico)** |
| **Replicaci√≥n entre regiones** | S3 Cross-Region Replication (manual) | ADLS Geo-Redundant Storage (manual) | Cloud Storage Dual/Multi-region (autom√°tico) |
| **Backup autom√°tico** | Debe configurarse (S3 Versioning) | Debe configurarse (Soft delete) | **Versionamiento autom√°tico opcional** |

**Requisitos de continuidad para el proyecto**

| Requisito | AWS | Azure | GCP |
|-----------|-----|-------|-----|
| Disponibilidad del warehouse > 99.9% | ‚úÖ Redshift 99.9% | ‚úÖ Synapse 99.9% | ‚úÖ **BigQuery 99.99%** |
| Recuperaci√≥n de datos hist√≥ricos (7 d√≠as) | ‚ö†Ô∏è Requiere snapshots programados | ‚ö†Ô∏è Requiere backups programados | ‚úÖ **Time Travel incluido (7 d√≠as gratis)** |
| Tolerancia a fallos de AZ | ‚úÖ Multi-AZ (configuraci√≥n) | ‚úÖ Zone-redundant (configuraci√≥n) | ‚úÖ **Autom√°tico en servicios serverless** |
| Backup autom√°tico sin configuraci√≥n | ‚ùå Requiere configuraci√≥n | ‚ùå Requiere configuraci√≥n | ‚úÖ **BigQuery snapshots autom√°ticos** |
| Re-ejecuci√≥n autom√°tica de jobs fallidos | ‚ö†Ô∏è Configurar en Step Functions | ‚ö†Ô∏è Configurar en Data Factory | ‚úÖ **Retry policy nativo en Dataproc** |

Las tres plataformas ofrecen resiliencia adecuada para el proyecto. **GCP destaca por redundancia autom√°tica sin configuraci√≥n**



### 1.3.6 Capacidades de red y latencia

La latencia de red impacta directamente la velocidad de carga de datos (web scraping ‚Üí cloud), ejecuci√≥n de jobs distribuidos (PySpark) y consultas interactivas desde Power BI. Para un proyecto operado desde Lima, Per√∫, la proximidad geogr√°fica de la regi√≥n es cr√≠tica.

| Aspecto | AWS | Azure | GCP |
|---------|-----|-------|-----|
| **Backbone de red** | Internet p√∫blico + AWS Direct Connect (privado) | Internet p√∫blico + Azure ExpressRoute (privado) | **Google Global Network privado (100% propio)** |
| **Distancia f√≠sica desde Lima** | S√£o Paulo: ~3,150 km | Brazil South: ~3,150 km | **Santiago: ~2,200 km** (30% m√°s cerca) |
| **Latencia promedio desde Lima** | us-east-1: ~170 ms<br>sa-east-1: **~85 ms** | eastus: ~175 ms<br>brazilsouth: **~90 ms** | us-central1: ~180 ms<br>**southamerica-west1: ~45 ms** |
| **Ancho de banda entre regiones** | Hasta 100 Gbps (inter-region) | Hasta 100 Gbps (inter-region) | **Petabits/segundo (Google Global Network)** |
| **Peering con ISPs locales** | Peering extenso en Sudam√©rica | Peering con carriers principales | **Peering directo con > 10,000 ISPs globalmente** |
| **CDN integrado** | Amazon CloudFront | Azure CDN / Front Door | **Google Cloud CDN** (integrado con Global Network) |


**Requisitos de red para el proyecto**

| Requisito | AWS | Azure | GCP |
|-----------|-----|-------|-----|
| Latencia < 100 ms desde Lima | ‚úÖ S√£o Paulo ~85 ms | ‚úÖ Brazil South ~90 ms | ‚úÖ **Santiago ~45 ms** |
| Upload r√°pido de datos scraping | ‚úÖ Aceptable (~15 seg) | ‚úÖ Aceptable (~15 seg) | ‚úÖ **R√°pido (~10 seg)** |
| Consultas Power BI responsivas | ‚úÖ ~1.5-2 seg | ‚úÖ ~1.6-2.2 seg | ‚úÖ **~0.8-1.2 seg** |
| Sin costos de ancho de banda inesperados | ‚úÖ Predecible | ‚úÖ Predecible | ‚úÖ **Predecible (menor costo inter-regi√≥n)** |
| Redundancia de rutas de red | ‚úÖ M√∫ltiples carriers | ‚úÖ M√∫ltiples carriers | ‚úÖ **Google Global Network (m√°s resiliente)** |


**AWS y Azure ofrecen capacidades de red robustas**, pero **la ventaja geogr√°fica de GCP es resaltante**, da m√°s r√°pida sin costos adicionales.

---

## 1.4 Decisi√≥n final

> **‚ÄúSe seleccion√≥ Google Cloud Platform porque  satisface simult√°neamente los requerimientos t√©cnicos, financieros y operativos del proyecto BI Scotiabank. GCP permite mantener la arquitectura Medallion, ejecutar en modo serverless y operar desde la regi√≥n m√°s cercana al Per√∫. Adem√°s, su free tier facilita el desarrollo acad√©mico sin costos.‚Äù**

