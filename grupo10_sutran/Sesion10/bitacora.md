# ğŸ“ BitÃ¡cora del Pipeline BI en AWS â€“ Grupo 10
ğŸ‘¥ Grupo: 10  
ğŸ—“ï¸ Fecha: 09-11-2025  
ğŸ“¦ Proyecto: Pipeline de Business Intelligence Cloud  
ğŸš€ Servicios utilizados: S3, Glue, Athena *(QuickSight: pendiente)*

---

## ğŸ“ 1. Ingesta de datos (S3 â€“ zona *raw*)

- Se trabajÃ³ el archivo original `Amazon Sale Report.csv` desde el entorno local en **Visual Studio Code**.
- Se realizÃ³ limpieza de datos y ajustes de columnas.
- Se resolvieron errores en consola relacionados a:
  - Secuencias de escape en rutas (`\U`, `\n`) con uso de `r'path'`.
  - Unicode (`ğŸ“¦`) y codificaciÃ³n de consola Windows.
- Se exportÃ³ el archivo limpio como `ecommerce_clean.csv`.

### ğŸª£ Carga a S3
- Bucket: `si807u-10-bi`
- Ruta destino:  
```

s3://si807u-10-bi/raw/ecommerce/ecommerce_clean.csv

```
- Se configurÃ³ AWS CLI con `Access Key ID` y `Secret Access Key` generados por IAM.
- Se creÃ³ una polÃ­tica IAM inline llamada `AllowS3Grupo10` con permisos iniciales de:
- `s3:GetObject`
- `s3:PutObject`
- `s3:ListBucket`

---

## ğŸ” 2. Glue Crawler y CatÃ¡logo de Datos

### âœ… Base de datos
- Nombre: `raw_data`

### âœ… Crawler creado
- Nombre: `ecommerce_raw_crawler`
- Ruta: `s3://si807u-10-bi/raw/ecommerce/`
- Rol: `AWSGlueServiceRole-lider`
- Target: `raw_data`
- Tabla generada: `ecommerce_clean`

### âš ï¸ Validaciones
- Se revisaron y ajustaron los tipos de datos.
- Se eliminÃ³ la columna innecesaria `unnamed:_22`.

---

## ğŸ” 3. TransformaciÃ³n con Glue Job (ETL â€“ PySpark)

### ğŸ§¾ Script: `transform_raw_to_curated.py`

UbicaciÃ³n:  
```
s3://si807u-10-bi/scripts/transform_raw_to_curated.py
```

### ğŸ”§ Funcionalidad:
- ConversiÃ³n de columna `date` a `order_date` (tipo fecha)
- CreaciÃ³n de columnas `year` y `month` para particionado
- Limpieza de columnas no necesarias
- Escritura en formato **Parquet particionado por aÃ±o y mes**

### ğŸ“Œ CÃ³digo base:
```python
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.utils import getResolvedOptions
from pyspark.sql.functions import year, month, to_date, col
import sys

args = getResolvedOptions(sys.argv, ['SOURCE', 'TARGET'])

sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session

df = spark.read.option("header", True).csv(args['SOURCE'])

df = df.drop("unnamed:_22")
df = df.withColumn("order_date", to_date(col("date"), "yyyy-MM-dd"))
df = df.withColumn("year", year("order_date"))
df = df.withColumn("month", month("order_date"))

df.write.mode("overwrite").partitionBy("year", "month").parquet(args['TARGET'])
```

### âš™ï¸ Job ejecutado en Glue

* Nombre del Job: `transform_raw_to_curated`
* ParÃ¡metros:

  * `--SOURCE`: `s3://si807u-10-bi/raw/ecommerce/`
  * `--TARGET`: `s3://si807u-10-bi/curated/ecommerce/`

### âœ… Problemas solucionados:

* âŒ Error 403 al leer el script desde S3 â†’ se agregÃ³ permiso `s3:GetObject`
* âŒ Error 403 al escribir en `curated/` â†’ se ampliÃ³ polÃ­tica con `s3:PutObject`

---

## ğŸ“Š 4. Athena â€“ Consultas analÃ­ticas

### âœ… `00_create_analytics_db.sql`

```sql
CREATE DATABASE IF NOT EXISTS analytics_db;
```

---

### âœ… `10_create_sales_curated.sql` (adaptado a columnas del dataset)

```sql
CREATE EXTERNAL TABLE IF NOT EXISTS analytics_db.sales_curated (
  order_id string,
  order_date date,
  status string,
  fulfilment string,
  sales_channel string,
  ship_service_level string,
  style string,
  sku string,
  category string,
  size string,
  asin string,
  courier_status string,
  quantity int,
  currency string,
  sales double,
  ship_city string,
  ship_state string,
  ship_postal_code string,
  ship_country string,
  promotion_ids string,
  b2b boolean,
  fulfilled_by string
)
PARTITIONED BY (year int, month int)
STORED AS PARQUET
LOCATION 's3://si807u-10-bi/curated/ecommerce/';
```

### âœ… Particionado:

```sql
MSCK REPAIR TABLE analytics_db.sales_curated;
```

---

### âœ… `20_kpi_sales_summary.sql` (adaptado)

```sql
SELECT 
  category,
  SUM(sales) AS total_sales,
  COUNT(order_id) AS total_orders,
  SUM(quantity) AS total_quantity
FROM analytics_db.sales_curated
GROUP BY category
ORDER BY total_sales DESC;
```

---

## ğŸ“ˆ 5. QuickSight â€“ *Pendiente*

### âš ï¸ No se pudo completar este paso

> Al intentar crear la cuenta de QuickSight, el formulario se recargaba sin avanzar. Por tanto, no se pudo conectar con Athena ni generar el Dashboard â€œVentas por CategorÃ­aâ€.

Se deja la intenciÃ³n documentada para referencias futuras.

---

## ğŸ“Œ Extras y mejoras realizadas

* Se consolidÃ³ una polÃ­tica IAM inline (`AllowScriptAccess`) con:

  * Acceso completo a `si807u-10-bi` (`Get`, `Put`, `Delete`, `List`)
  * Permisos para ejecutar Glue Jobs y ver logs (`glue:*`, `logs:*`)
* Se estructurÃ³ el cÃ³digo PySpark segÃºn buenas prÃ¡cticas
* Se adaptaron scripts SQL para Athena segÃºn el dataset real

---

## âœ… Checklist Final de Entrega

| Tarea                               | Estado                             |
| ----------------------------------- | ---------------------------------- |
| CSV limpio cargado a S3/raw         | âœ…                                  |
| Crawler creado y tabla en Glue      | âœ…                                  |
| Glue Job ejecutado con particionado | âœ…                                  |
| Tabla externa creada en Athena      | âœ…                                  |
| Particiones registradas (`MSCK`)    | âœ…                                  |
| KPIs ejecutados en Athena           | âœ…                                  |
| Dashboard en QuickSight             | âš ï¸ *Pendiente por error de cuenta* |
| BitÃ¡cora actualizada                | âœ…                                  |

---

## ğŸ“Œ PrÃ³ximos pasos sugeridos

* Resolver problema de creaciÃ³n de cuenta QuickSight
* Crear dataset desde Athena
* DiseÃ±ar y publicar dashboard BI

