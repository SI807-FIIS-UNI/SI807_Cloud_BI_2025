{"cells": [{"cell_type": "code", "execution_count": 13, "id": "7b2e3083-0bd7-4709-8e67-1e8f6ac457b7", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, sum as _sum, avg, count, round, when, to_timestamp, hour\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import IntegerType\n\n# -----------------------------\n# Configuraci\u00f3n de Spark\n# -----------------------------\nspark = SparkSession.builder \\\n    .appName(\"Nettalco Big Data Processing\") \\\n    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n    .getOrCreate()\n\n# Ruta de salida en Cloud Storage\noutput_path = \"gs://nettalco-data-bd_grupo05/curated/\"\n# Rutas de los archivos CSV\ndetalle_path = \"gs://nettalco-data-bd_grupo05/detalle-produccion-costura.csv\"\ncliente_path = \"gs://nettalco-data-bd_grupo05/produccion-costura-cliente.csv\"\nlinea_path = \"gs://nettalco-data-bd_grupo05/produccion-costura-linea-cliente.csv\"\nsegundas_path = \"gs://nettalco-data-bd_grupo05/segundas-prendas.csv\"\n\n# Ruta de salida\noutput_path = \"gs://nettalco-data-bd_grupo05/curated/\"\n\n# Cargar los datos\ndetalle_produccion = spark.read.csv(detalle_path, header=True, inferSchema=True)\nproduccion_costura_cliente = spark.read.csv(cliente_path, header=True, inferSchema=True)\nproduccion_costura_linea_client = spark.read.csv(linea_path, header=True, inferSchema=True)\nsegundas_prendas = spark.read.csv(segundas_path, header=True, inferSchema=True)\n\n# Convertir columnas num\u00e9ricas a IntegerType\ndetalle_produccion = detalle_produccion.withColumn(\"PRENDAS\", col(\"PRENDAS\").cast(IntegerType()))\nproduccion_costura_cliente = produccion_costura_cliente.withColumn(\"PRENDAS\", col(\"PRENDAS\").cast(IntegerType()))\nproduccion_costura_linea_client = produccion_costura_linea_client.withColumn(\"PRENDAS\", col(\"PRENDAS\").cast(IntegerType()))\nsegundas_prendas = segundas_prendas.withColumn(\"FALLAS_SEGUNDAS\", col(\"FALLAS_SEGUNDAS\").cast(IntegerType())) \\\n                                   .withColumn(\"INSPECCION_TOTAL\", col(\"INSPECCION_TOTAL\").cast(IntegerType()))\n\n# -----------------------------\n# Preprocesamiento de FECHA_TERMINO\n# -----------------------------\ndetalle_produccion = detalle_produccion.withColumn(\n    \"FECHA_TERMINO_TS\",\n    to_timestamp(\"FECHA_TERMINO\", \"dd/MM/yyyy HH:mm:ss\")\n)"}, {"cell_type": "code", "execution_count": 17, "id": "f5855c4e-77a8-4453-b2bf-1a19526fb888", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# -----------------------------\n# Total prendas por talla\n# -----------------------------\ndetalle_produccion.groupBy(\"TALLA\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .orderBy(\"TALLA\") \\\n    .write.csv(f\"{output_path}total_prendas_por_talla\", header=True)\n\n# -----------------------------\n# Volumen de ventas por cliente\n# -----------------------------\nproduccion_cliente.groupBy(\"TCODICLIE\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .orderBy(\"TCODICLIE\") \\\n    .write.csv(f\"{output_path}volumen_ventas_por_cliente\", header=True)\n\n# -----------------------------\n# Fecha ventas\n# -----------------------------\nproduccion_cliente.groupBy(\"FECHA\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .orderBy(\"FECHA\") \\\n    .write.csv(f\"{output_path}fecha_ventas\", header=True)\n\n# -----------------------------\n# Tendencias por franja horaria\n# -----------------------------\n# Convertir FECHA_TERMINO a timestamp y extraer hora\ndetalle_produccion = detalle_produccion.withColumn(\n    \"FECHA_TERMINO_TS\",\n    to_timestamp(\"FECHA_TERMINO\", \"dd/MM/yyyy HH:mm:ss\")\n)\ndetalle_produccion = detalle_produccion.withColumn(\"HORA\", hour(\"FECHA_TERMINO_TS\"))\n\ntendencias = detalle_produccion.withColumn(\n    \"FRANJA_HORARIA\",\n    when((col(\"HORA\") >= 6) & (col(\"HORA\") <= 11), \"Ma\u00f1ana\")\n    .when((col(\"HORA\") >= 12) & (col(\"HORA\") <= 17), \"Tarde\")\n    .when((col(\"HORA\") >= 18) & (col(\"HORA\") <= 23), \"Noche\")\n    .otherwise(\"Madrugada\")\n).groupBy(\"ORDEN_PRODUCCION\", \"FRANJA_HORARIA\") \\\n .agg(count(\"*\").alias(\"TRANSACCIONES\"), _sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n .orderBy(\"ORDEN_PRODUCCION\", \"FRANJA_HORARIA\")\n\ntendencias.write.csv(f\"{output_path}tendencias_ventas_por_franja_horaria\", header=True)\n\n# -----------------------------\n# Productos m\u00e1s vendidos\n# -----------------------------\ndetalle_produccion.groupBy(\"ESTILO\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .orderBy(\"ESTILO\") \\\n    .write.csv(f\"{output_path}productos_mas_vendidos\", header=True)\n# -----------------------------\n# Eficiencia operativa\n# -----------------------------\nsegundas_prendas.groupBy(\"FECHA\") \\\n    .agg(\n        round(\n            (1 - (_sum(\"FALLAS_SEGUNDAS\") / _sum(\"INSPECCION_TOTAL\"))) * 100, 2\n        ).alias(\"EFICIENCIA_PORCENTUAL\")\n    ) \\\n    .orderBy(\"FECHA\") \\\n    .write.csv(f\"{output_path}eficiencia_operativa\", header=True)\n\n# -----------------------------\n# \u00cdndice de ventas por cliente y l\u00ednea\n# -----------------------------\nproduccion_costura_linea_client.groupBy(\"TCODICLIE\", \"LINEA\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .orderBy(\"TCODICLIE\") \\\n    .write.csv(f\"{output_path}indice_ventas_cliente\", header=True)\n\n# -----------------------------\n# Predicci\u00f3n de ventas (promedio m\u00f3vil 7 d\u00edas)\n# -----------------------------\ndetalle_produccion.groupBy(\"FECHA_TERMINO_TS\", \"ESTILO\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .withColumn(\n        \"PROMEDIO_MOVIL\",\n        avg(\"TOTAL_PRENDAS\").over(Window.partitionBy(\"ESTILO\").orderBy(\"FECHA_TERMINO_TS\").rowsBetween(-6, 0))\n    ) \\\n    .write.csv(f\"{output_path}prediccion_ventas\", header=True)\n\n# -----------------------------\n# Comportamiento de clientes\n# -----------------------------\nproduccion_costura_cliente.groupBy(\"TCODICLIE\") \\\n    .agg(count(\"FECHA\").alias(\"FRECUENCIA_COMPRA\"), avg(\"PRENDAS\").alias(\"PROMEDIO_PRENDAS\")) \\\n    .orderBy(\"TCODICLIE\") \\\n    .write.csv(f\"{output_path}comportamiento_clientes\", header=True)"}, {"cell_type": "markdown", "id": "7e4babc1-dcdb-49cb-b2a7-ef4b19c75886", "metadata": {}, "source": "\u2705 SCRIPT FINAL CON .mode(\"overwrite\") EN TODAS LAS SALIDAS"}, {"cell_type": "code", "execution_count": null, "id": "6f7c1ed7-7139-4cb2-a0c0-96345dd1ce58", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, sum as _sum, avg, count, round, when, to_timestamp, hour\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import IntegerType\n\n# -----------------------------\n# Configuraci\u00f3n de Spark\n# -----------------------------\nspark = SparkSession.builder \\\n    .appName(\"Nettalco Big Data Processing\") \\\n    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n    .getOrCreate()\n\n# Rutas Cloud Storage\noutput_path = \"gs://nettalco-data-bd_grupo05/curated/\"\ndetalle_path = \"gs://nettalco-data-bd_grupo05/detalle-produccion-costura.csv\"\ncliente_path = \"gs://nettalco-data-bd_grupo05/produccion-costura-cliente.csv\"\nlinea_path = \"gs://nettalco-data-bd_grupo05/produccion-costura-linea-cliente.csv\"\nsegundas_path = \"gs://nettalco-data-bd_grupo05/segundas-prendas.csv\"\n\n# Cargar los datos\ndetalle_produccion = spark.read.csv(detalle_path, header=True, inferSchema=True)\nproduccion_costura_cliente = spark.read.csv(cliente_path, header=True, inferSchema=True)\nproduccion_costura_linea_client = spark.read.csv(linea_path, header=True, inferSchema=True)\nsegundas_prendas = spark.read.csv(segundas_path, header=True, inferSchema=True)\n\n# Convertir columnas num\u00e9ricas\ndetalle_produccion = detalle_produccion.withColumn(\"PRENDAS\", col(\"PRENDAS\").cast(IntegerType()))\nproduccion_costura_cliente = produccion_costura_cliente.withColumn(\"PRENDAS\", col(\"PRENDAS\").cast(IntegerType()))\nproduccion_costura_linea_client = produccion_costura_linea_client.withColumn(\"PRENDAS\", col(\"PRENDAS\").cast(IntegerType()))\nsegundas_prendas = segundas_prendas.withColumn(\"FALLAS_SEGUNDAS\", col(\"FALLAS_SEGUNDAS\").cast(IntegerType())) \\\n                                   .withColumn(\"INSPECCION_TOTAL\", col(\"INSPECCION_TOTAL\").cast(IntegerType()))\n\n# -----------------------------\n# Procesar FECHA_TERMINO\n# -----------------------------\ndetalle_produccion = detalle_produccion.withColumn(\n    \"FECHA_TERMINO_TS\",\n    to_timestamp(\"FECHA_TERMINO\", \"dd/MM/yyyy HH:mm:ss\")\n)\n\n# -----------------------------\n# Total prendas por talla\n# -----------------------------\ndetalle_produccion.groupBy(\"TALLA\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .orderBy(\"TALLA\") \\\n    .write.mode(\"overwrite\").csv(f\"{output_path}total_prendas_por_talla\", header=True)\n\n# -----------------------------\n# Volumen de ventas por cliente\n# -----------------------------\nproduccion_costura_cliente.groupBy(\"TCODICLIE\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .orderBy(\"TCODICLIE\") \\\n    .write.mode(\"overwrite\").csv(f\"{output_path}volumen_ventas_por_cliente\", header=True)\n\n# -----------------------------\n# Fecha ventas\n# -----------------------------\nproduccion_costura_cliente.groupBy(\"FECHA\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .orderBy(\"FECHA\") \\\n    .write.mode(\"overwrite\").csv(f\"{output_path}fecha_ventas\", header=True)\n\n# -----------------------------\n# Tendencias por franja horaria\n# -----------------------------\ndetalle_produccion = detalle_produccion.withColumn(\"HORA\", hour(\"FECHA_TERMINO_TS\"))\n\ntendencias = detalle_produccion.withColumn(\n    \"FRANJA_HORARIA\",\n    when((col(\"HORA\") >= 6) & (col(\"HORA\") <= 11), \"Ma\u00f1ana\")\n    .when((col(\"HORA\") >= 12) & (col(\"HORA\") <= 17), \"Tarde\")\n    .when((col(\"HORA\") >= 18) & (col(\"HORA\") <= 23), \"Noche\")\n    .otherwise(\"Madrugada\")\n).groupBy(\"ORDEN_PRODUCCION\", \"FRANJA_HORARIA\") \\\n .agg(count(\"*\").alias(\"TRANSACCIONES\"), _sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n .orderBy(\"ORDEN_PRODUCCION\", \"FRANJA_HORARIA\")\n\ntendencias.write.mode(\"overwrite\").csv(f\"{output_path}tendencias_ventas_por_franja_horaria\", header=True)\n\n# -----------------------------\n# Productos m\u00e1s vendidos\n# -----------------------------\ndetalle_produccion.groupBy(\"ESTILO\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .orderBy(\"ESTILO\") \\\n    .write.mode(\"overwrite\").csv(f\"{output_path}productos_mas_vendidos\", header=True)\n\n# -----------------------------\n# Eficiencia operativa\n# -----------------------------\nsegundas_prendas.groupBy(\"FECHA\") \\\n    .agg(\n        round(\n            (1 - (_sum(\"FALLAS_SEGUNDAS\") / _sum(\"INSPECCION_TOTAL\"))) * 100, 2\n        ).alias(\"EFICIENCIA_PORCENTUAL\")\n    ) \\\n    .orderBy(\"FECHA\") \\\n    .write.mode(\"overwrite\").csv(f\"{output_path}eficiencia_operativa\", header=True)\n\n# -----------------------------\n# \u00cdndice de ventas por cliente y l\u00ednea\n# -----------------------------\nproduccion_costura_linea_client.groupBy(\"TCODICLIE\", \"LINEA\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .orderBy(\"TCODICLIE\") \\\n    .write.mode(\"overwrite\").csv(f\"{output_path}indice_ventas_cliente\", header=True)\n\n# -----------------------------\n# Predicci\u00f3n de ventas (promedio m\u00f3vil 7 d\u00edas)\n# -----------------------------\ndetalle_produccion.groupBy(\"FECHA_TERMINO_TS\", \"ESTILO\") \\\n    .agg(_sum(\"PRENDAS\").alias(\"TOTAL_PRENDAS\")) \\\n    .withColumn(\n        \"PROMEDIO_MOVIL\",\n        avg(\"TOTAL_PRENDAS\").over(Window.partitionBy(\"ESTILO\").orderBy(\"FECHA_TERMINO_TS\").rowsBetween(-6, 0))\n    ) \\\n    .write.mode(\"overwrite\").csv(f\"{output_path}prediccion_ventas\", header=True)\n\n# -----------------------------\n# Comportamiento de clientes\n# -----------------------------\nproduccion_costura_cliente.groupBy(\"TCODICLIE\") \\\n    .agg(count(\"FECHA\").alias(\"FRECUENCIA_COMPRA\"), avg(\"PRENDAS\").alias(\"PROMEDIO_PRENDAS\")) \\\n    .orderBy(\"TCODICLIE\") \\\n    .write.mode(\"overwrite\").csv(f\"{output_path}comportamiento_clientes\", header=True)"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}